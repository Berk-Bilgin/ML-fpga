{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354194, 64, 1) (88549, 64, 1)\n",
      "-10743.3 10743.31\n",
      "225500\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Samples are represented in 16-bit 2's complement\n",
    "\n",
    "# Get the directory where the script is located\n",
    "script_dir = os.getcwd()\n",
    "file_counter = 0\n",
    "Files = []\n",
    "badFiles = []\n",
    "# Construct the full path to the file\n",
    "file_path = os.path.join(script_dir, 'EDF', 'PD patient Frontal')\n",
    "for filename in os.listdir(file_path):\n",
    "    # Check if the file ends with .edf\n",
    "    if filename.endswith('.edf'):\n",
    "        file_counter = file_counter+1\n",
    "        Files.append(filename)\n",
    "for k in np.arange(file_counter):\n",
    "    path = os.path.join(file_path, Files[k])\n",
    "    try:\n",
    "        f = pyedflib.EdfReader(path)\n",
    "    except OSError:\n",
    "        badFiles.append(Files[k])     \n",
    "Files = [item for item in Files if item not in badFiles]\n",
    "n = f.signals_in_file\n",
    "n = n-9\n",
    "number_of_samples = f.getNSamples()[0]\n",
    "Nblocks = int((number_of_samples-250)/64)\n",
    "TotalBlocks=(5*Nblocks + int((223500-250)/64))*n\n",
    "fuller_data = np.ndarray(shape=(TotalBlocks, 64, 1))\n",
    "BlockCount=0\n",
    "multiplier = f.getPhysicalMaximum(0)/f.getDigitalMaximum(0)\n",
    "min_val = f.getPhysicalMinimum(0)\n",
    "max_val = f.getPhysicalMaximum(0)\n",
    "for index, name in enumerate(Files):\n",
    "    path = os.path.join(file_path, name)\n",
    "    f = pyedflib.EdfReader(path)\n",
    "    number_of_samples = f.getNSamples()[0]\n",
    "    Nblocks = int((number_of_samples-250)/64)\n",
    "    sigbufs = np.zeros(number_of_samples)\n",
    "    full_data64 = np.ndarray(shape=(Nblocks*n, 64, 1))\n",
    "    signalList = []  \n",
    "    BlockCount = BlockCount+Nblocks*n\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[:] = f.readSignal(i, digital=True)\n",
    "        sigbufs_new = sigbufs[250:]\n",
    "        signalList.append(sigbufs_new) \n",
    "        for j in np.arange(Nblocks):\n",
    "                full_data64[i*Nblocks+j] = signalList[i][j*64:(j+1)*64].reshape(64, 1)\n",
    "    fuller_data[BlockCount-Nblocks*n:BlockCount] = full_data64\n",
    "    f.close()\n",
    "#fuller_data = fuller_data + (2**15)\n",
    "train_data, val_data = train_test_split(fuller_data, test_size=0.2, random_state=45)\n",
    "print(train_data.shape, val_data.shape)\n",
    "print(min_val, max_val)\n",
    "print(number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210253, 128, 1) (11066, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Samples are represented in 16-bit 2's complement\n",
    "\n",
    "# Get the directory where the script is located\n",
    "script_dir = os.getcwd()\n",
    "file_counter = 0\n",
    "Files = []\n",
    "badFiles = []\n",
    "# Construct the full path to the file\n",
    "file_path = os.path.join(script_dir, 'EDF', 'PD patient Frontal')\n",
    "for filename in os.listdir(file_path):\n",
    "    # Check if the file ends with .edf\n",
    "    if filename.endswith('.edf'):\n",
    "        file_counter = file_counter+1\n",
    "        Files.append(filename)\n",
    "for k in np.arange(file_counter):\n",
    "    path = os.path.join(file_path, Files[k])\n",
    "    try:\n",
    "        f = pyedflib.EdfReader(path)\n",
    "    except OSError:\n",
    "        badFiles.append(Files[k])     \n",
    "Files = [item for item in Files if item not in badFiles]\n",
    "n = f.signals_in_file\n",
    "n = n-9\n",
    "number_of_samples = f.getNSamples()[0]\n",
    "Nblocks = int((number_of_samples-250)/128)\n",
    "TotalBlocks=(5*Nblocks + int((223500-250)/128))*n\n",
    "fuller_data = np.ndarray(shape=(TotalBlocks, 128, 1))\n",
    "BlockCount=0\n",
    "multiplier = f.getPhysicalMaximum(0)/f.getDigitalMaximum(0)\n",
    "for index, name in enumerate(Files):\n",
    "    path = os.path.join(file_path, name)\n",
    "    f = pyedflib.EdfReader(path)\n",
    "    number_of_samples = f.getNSamples()[0]\n",
    "    Nblocks = int((number_of_samples-250)/128)\n",
    "    sigbufs = np.zeros(number_of_samples)\n",
    "    full_data128 = np.ndarray(shape=(Nblocks*n, 128, 1))\n",
    "    signalList = []  \n",
    "    BlockCount = BlockCount+Nblocks*n\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[:] = f.readSignal(i, digital=True)\n",
    "        sigbufs_new = sigbufs[250:]\n",
    "        signalList.append(sigbufs_new) \n",
    "        for j in np.arange(Nblocks):\n",
    "                full_data128[i*Nblocks+j] = signalList[i][j*128:(j+1)*128].reshape(128, 1)\n",
    "    fuller_data[BlockCount-Nblocks*n:BlockCount] = full_data128\n",
    "    f.close()\n",
    "train_data, test_data = train_test_split(fuller_data, test_size=0.05, random_state=42)\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12-bit Unsigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4095.0 0.0\n",
      "Percentage of Clipped Values: 0.07924673569090872\n",
      "(398468, 64, 1) (44275, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Samples are represented in 16-bit 2's complement\n",
    "\n",
    "# Get the directory where the script is located\n",
    "script_dir = os.getcwd()\n",
    "file_counter = 0\n",
    "Files = []\n",
    "badFiles = []\n",
    "# Construct the full path to the file\n",
    "file_path = os.path.join(script_dir, 'EDF', 'PD patient Frontal')\n",
    "for filename in os.listdir(file_path):\n",
    "    # Check if the file ends with .edf\n",
    "    if filename.endswith('.edf'):\n",
    "        file_counter = file_counter+1\n",
    "        Files.append(filename)\n",
    "for k in np.arange(file_counter):\n",
    "    path = os.path.join(file_path, Files[k])\n",
    "    try:\n",
    "        f = pyedflib.EdfReader(path)\n",
    "    except OSError:\n",
    "        badFiles.append(Files[k])     \n",
    "Files = [item for item in Files if item not in badFiles]\n",
    "n = f.signals_in_file\n",
    "n = n-9\n",
    "number_of_samples = f.getNSamples()[0]\n",
    "Nblocks = int((number_of_samples-250)/64)\n",
    "TotalBlocks=(5*Nblocks + int((223500-250)/64))*n\n",
    "fuller_data = np.ndarray(shape=(TotalBlocks, 64, 1))\n",
    "BlockCount=0\n",
    "count_of = 0\n",
    "multiplier = f.getPhysicalMaximum(0)/f.getDigitalMaximum(0)\n",
    "for index, name in enumerate(Files):\n",
    "    path = os.path.join(file_path, name)\n",
    "    f = pyedflib.EdfReader(path)\n",
    "    number_of_samples = f.getNSamples()[0]\n",
    "    Nblocks = int((number_of_samples-250)/64)\n",
    "    sigbufs = np.zeros(number_of_samples)\n",
    "    full_data64 = np.ndarray(shape=(Nblocks*n, 64, 1))\n",
    "    signalList = []  \n",
    "    BlockCount = BlockCount+Nblocks*n\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[:] = f.readSignal(i, digital=True)\n",
    "        sigbufs_new = sigbufs[250:]\n",
    "        absoule = np.abs(sigbufs_new)\n",
    "        if np.any(absoule > (2**11 )):\n",
    "            boolean_mask = absoule > (2**11 -1)\n",
    "            count_of = count_of + np.sum(boolean_mask)\n",
    "        signalList.append(sigbufs_new) \n",
    "        for j in np.arange(Nblocks):\n",
    "                full_data64[i*Nblocks+j] = signalList[i][j*64:(j+1)*64].reshape(64, 1)\n",
    "    fuller_data[BlockCount-Nblocks*n:BlockCount] = full_data64\n",
    "    f.close()\n",
    "fuller_data = fuller_data + (2**11)\n",
    "train_data, val_data = train_test_split(fuller_data, test_size=0.1, random_state=31)\n",
    "clipped_data = train_data\n",
    "overMask = clipped_data > (2**12 - 1)\n",
    "underMask = clipped_data < 0\n",
    "total = np.sum(overMask)\n",
    "total = total + np.sum(underMask)\n",
    "clipped_data[overMask] = (2**12 - 1)\n",
    "clipped_data[underMask] = 0\n",
    "print(np.max(clipped_data), np.min(clipped_data))\n",
    "percentage = total/(TotalBlocks*64)*100\n",
    "print(f'Percentage of Clipped Values:', percentage)\n",
    "print(clipped_data.shape, val_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRD Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def prd_loss(y_true, y_pred):\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRD (for signed 16-bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 14:07:06.531346: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-06 14:07:06.531827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-06 14:07:06.532619: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-06 14:07:06.539390: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-06 14:07:07.353018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def prd_loss_dig2phy(y_true, y_pred):\n",
    "    y_true = (y_true)*multiplier\n",
    "    y_pred = (y_pred)*multiplier\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsigned PRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def prd_dig2phy(y_true, y_pred):\n",
    "    y_true = (y_true - 2**15)*multiplier\n",
    "    y_pred = (y_pred - 2**15)*multiplier\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norm PRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def prd_dig2phy1(y_true, y_pred):\n",
    "    y_true = (y_true - 2**11)*multiplier\n",
    "    y_pred = (y_pred - 2**11)*multiplier\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def prdNorm(y_true, y_pred):\n",
    "    y_true = ((y_true*(10743.3+10743.31))-10743.3)\n",
    "    y_pred = ((y_pred*(10743.3+10743.31))-10743.3)\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 16-bit Integer (Linear Actv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 64, 1)]           0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 16)                2720      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 64, 1)             2337      \n",
      "=================================================================\n",
      "Total params: 5,057\n",
      "Trainable params: 5,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "5535/5535 [==============================] - 68s 12ms/step - loss: 29.4421 - val_loss: 19.6402\n",
      "Epoch 2/30\n",
      "5535/5535 [==============================] - 45s 8ms/step - loss: 19.8902 - val_loss: 21.0483\n",
      "Epoch 3/30\n",
      "5535/5535 [==============================] - 55s 10ms/step - loss: 19.9416 - val_loss: 19.4119\n",
      "Epoch 4/30\n",
      "5535/5535 [==============================] - 48s 9ms/step - loss: 19.7451 - val_loss: 19.4912\n",
      "Epoch 5/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 19.7247 - val_loss: 19.6096\n",
      "Epoch 6/30\n",
      "5535/5535 [==============================] - 47s 9ms/step - loss: 19.6481 - val_loss: 19.3215\n",
      "Epoch 7/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 19.6046 - val_loss: 19.2500\n",
      "Epoch 8/30\n",
      "5535/5535 [==============================] - 45s 8ms/step - loss: 19.4412 - val_loss: 19.0745\n",
      "Epoch 9/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 19.2747 - val_loss: 18.9757\n",
      "Epoch 10/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 19.0596 - val_loss: 18.8164\n",
      "Epoch 11/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 18.7723 - val_loss: 20.7569\n",
      "Epoch 12/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 18.7167 - val_loss: 18.8148\n",
      "Epoch 13/30\n",
      "5535/5535 [==============================] - 47s 8ms/step - loss: 18.8838 - val_loss: 18.9252\n",
      "Epoch 14/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 18.5472 - val_loss: 18.8627\n",
      "Epoch 15/30\n",
      "5535/5535 [==============================] - 45s 8ms/step - loss: 18.9460 - val_loss: 18.8373\n",
      "Epoch 16/30\n",
      "5535/5535 [==============================] - 47s 9ms/step - loss: 18.8548 - val_loss: 18.7757\n",
      "Epoch 17/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 18.6998 - val_loss: 18.8123\n",
      "Epoch 18/30\n",
      "5535/5535 [==============================] - 45s 8ms/step - loss: 18.7415 - val_loss: 18.7817\n",
      "Epoch 19/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 18.7718 - val_loss: 18.8813\n",
      "Epoch 20/30\n",
      "5535/5535 [==============================] - 45s 8ms/step - loss: 18.6797 - val_loss: 18.9160\n",
      "Epoch 21/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 18.7971 - val_loss: 18.7952\n",
      "Epoch 22/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 19.0006 - val_loss: 18.7871\n",
      "Epoch 23/30\n",
      "5535/5535 [==============================] - 47s 9ms/step - loss: 18.7569 - val_loss: 18.7654\n",
      "Epoch 24/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 18.8155 - val_loss: 18.7477\n",
      "Epoch 25/30\n",
      "5535/5535 [==============================] - 48s 9ms/step - loss: 18.6365 - val_loss: 18.7580\n",
      "Epoch 26/30\n",
      "5535/5535 [==============================] - 51s 9ms/step - loss: 18.7000 - val_loss: 18.8750\n",
      "Epoch 27/30\n",
      "5535/5535 [==============================] - 49s 9ms/step - loss: 18.7421 - val_loss: 18.8976\n",
      "Epoch 28/30\n",
      "5535/5535 [==============================] - 46s 8ms/step - loss: 18.5384 - val_loss: 18.8092\n",
      "Epoch 29/30\n",
      "5535/5535 [==============================] - 47s 8ms/step - loss: 18.9680 - val_loss: 18.7773\n",
      "Epoch 30/30\n",
      "5535/5535 [==============================] - 48s 9ms/step - loss: 18.7769 - val_loss: 20.0399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3106c19d0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Conv1DTranspose, Dense, Flatten, Reshape\n",
    "# Define the input shape for single-channel EEG data with 64 samples\n",
    "input_shape = (64, 1)\n",
    "\n",
    "# Define the encoder\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = Conv1D(16, kernel_size=3, activation='linear', padding='same')(input_layer)\n",
    "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "x = Conv1D(8, kernel_size=3, activation='linear', padding='same')(x)\n",
    "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "x = Conv1D(8, kernel_size=3, activation='linear', padding='same')(x)\n",
    "encoded = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "\n",
    "# Flatten and bottleneck layer with 16 features\n",
    "x = Flatten()(x)\n",
    "bottleneck = Dense(16, activation='linear')(x)\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(input_layer, bottleneck, name=\"encoder\")\n",
    "\n",
    "# Define the decoder using Conv1DTranspose\n",
    "decoder_input = Input(shape=(16,))\n",
    "x = Dense(8 * 8, activation='linear')(decoder_input)  # Match the flattened dimension before upsampling\n",
    "x = Reshape((8, 8))(x)\n",
    "x = Conv1D(8, kernel_size=3, activation='linear', padding='same')(x)\n",
    "x = Conv1DTranspose(8, kernel_size=3, strides=2, activation='linear', padding='same')(x)\n",
    "x = Conv1D(8, kernel_size=3, activation='linear', padding='same')(x)\n",
    "x = Conv1DTranspose(8, kernel_size=3, strides=2, activation='linear', padding='same')(x)\n",
    "x = Conv1D(16, kernel_size=3, activation='linear', padding='same')(x)\n",
    "decoded = Conv1DTranspose(1, kernel_size=3, strides=2, activation='linear', padding='same')(x)\n",
    "\n",
    "# Decoder model\n",
    "decoder = Model(decoder_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Autoencoder model (combining encoder and decoder)\n",
    "autoencoder_input = input_layer\n",
    "autoencoder_output = decoder(encoder(autoencoder_input))\n",
    "autoencoder = Model(autoencoder_input, autoencoder_output, name=\"autoencoder\")\n",
    "autoencoder.compile(optimizer='adam', loss=prd_loss)\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(train_data, train_data, epochs=30, batch_size=64, validation_data=(val_data, val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 1)]           0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 16)                2720      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 64, 1)             2337      \n",
      "=================================================================\n",
      "Total params: 5,057\n",
      "Trainable params: 5,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10377/10377 [==============================] - 134s 11ms/step - loss: 105.4405 - val_loss: 100.6105\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 100.61047, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "10377/10377 [==============================] - 105s 10ms/step - loss: 100.4405 - val_loss: 100.0208\n",
      "\n",
      "Epoch 00002: val_loss improved from 100.61047 to 100.02081, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "10377/10377 [==============================] - 107s 10ms/step - loss: 100.4728 - val_loss: 100.0829\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 100.02081\n",
      "Epoch 4/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 100.4661 - val_loss: 100.0434\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 100.02081\n",
      "Epoch 5/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 100.4635 - val_loss: 101.8585\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 100.02081\n",
      "Epoch 6/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 100.4668 - val_loss: 100.7712\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 100.02081\n",
      "Epoch 7/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 100.4278 - val_loss: 100.7032\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 100.02081\n",
      "Epoch 8/50\n",
      "10377/10377 [==============================] - 101s 10ms/step - loss: 100.5382 - val_loss: 100.2578\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 100.02081\n",
      "Epoch 9/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 100.4814 - val_loss: 103.7315\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 100.02081\n",
      "Epoch 10/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 100.4994 - val_loss: 100.9921\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 100.02081\n",
      "Epoch 11/50\n",
      "10377/10377 [==============================] - 99s 10ms/step - loss: 100.4568 - val_loss: 100.0171\n",
      "\n",
      "Epoch 00011: val_loss improved from 100.02081 to 100.01705, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 100.5278 - val_loss: 100.4953\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 100.01705\n",
      "Epoch 13/50\n",
      "10377/10377 [==============================] - 101s 10ms/step - loss: 100.5168 - val_loss: 100.2000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 100.01705\n",
      "Epoch 14/50\n",
      "10377/10377 [==============================] - 101s 10ms/step - loss: 100.4772 - val_loss: 100.0300\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 100.01705\n",
      "Epoch 15/50\n",
      "10377/10377 [==============================] - 101s 10ms/step - loss: 100.4118 - val_loss: 57.9566\n",
      "\n",
      "Epoch 00015: val_loss improved from 100.01705 to 57.95657, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 54.3567 - val_loss: 58.7819\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 57.95657\n",
      "Epoch 17/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 45.0083 - val_loss: 36.5573\n",
      "\n",
      "Epoch 00017: val_loss improved from 57.95657 to 36.55732, saving model to best_model.h5\n",
      "Epoch 18/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 43.3128 - val_loss: 42.6552\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 36.55732\n",
      "Epoch 19/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 42.9392 - val_loss: 82.4741\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 36.55732\n",
      "Epoch 20/50\n",
      "10377/10377 [==============================] - 98s 9ms/step - loss: 42.1488 - val_loss: 38.5135\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 36.55732\n",
      "Epoch 21/50\n",
      "10377/10377 [==============================] - 104s 10ms/step - loss: 40.5780 - val_loss: 32.6787\n",
      "\n",
      "Epoch 00021: val_loss improved from 36.55732 to 32.67867, saving model to best_model.h5\n",
      "Epoch 22/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 40.6793 - val_loss: 34.5605\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 32.67867\n",
      "Epoch 23/50\n",
      "10377/10377 [==============================] - 105s 10ms/step - loss: 40.4363 - val_loss: 44.8777\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 32.67867\n",
      "Epoch 24/50\n",
      "10377/10377 [==============================] - 104s 10ms/step - loss: 39.1803 - val_loss: 27.0239\n",
      "\n",
      "Epoch 00024: val_loss improved from 32.67867 to 27.02389, saving model to best_model.h5\n",
      "Epoch 25/50\n",
      "10377/10377 [==============================] - 98s 9ms/step - loss: 39.2131 - val_loss: 26.6716\n",
      "\n",
      "Epoch 00025: val_loss improved from 27.02389 to 26.67162, saving model to best_model.h5\n",
      "Epoch 26/50\n",
      "10377/10377 [==============================] - 103s 10ms/step - loss: 39.1093 - val_loss: 21.5166\n",
      "\n",
      "Epoch 00026: val_loss improved from 26.67162 to 21.51665, saving model to best_model.h5\n",
      "Epoch 27/50\n",
      "10377/10377 [==============================] - 104s 10ms/step - loss: 40.0009 - val_loss: 25.6050\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 21.51665\n",
      "Epoch 28/50\n",
      "10377/10377 [==============================] - 103s 10ms/step - loss: 38.6857 - val_loss: 72.9164\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 21.51665\n",
      "Epoch 29/50\n",
      "10377/10377 [==============================] - 101s 10ms/step - loss: 38.9214 - val_loss: 33.8119\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 21.51665\n",
      "Epoch 30/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 38.4897 - val_loss: 27.0876\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 21.51665\n",
      "Epoch 31/50\n",
      "10377/10377 [==============================] - 104s 10ms/step - loss: 36.0496 - val_loss: 39.9760\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 21.51665\n",
      "Epoch 32/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 36.7204 - val_loss: 24.1337\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 21.51665\n",
      "Epoch 33/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 38.4713 - val_loss: 29.4284\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 21.51665\n",
      "Epoch 34/50\n",
      "10377/10377 [==============================] - 101s 10ms/step - loss: 36.2143 - val_loss: 20.4940\n",
      "\n",
      "Epoch 00034: val_loss improved from 21.51665 to 20.49403, saving model to best_model.h5\n",
      "Epoch 35/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 35.9471 - val_loss: 54.3918\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 20.49403\n",
      "Epoch 36/50\n",
      "10377/10377 [==============================] - 103s 10ms/step - loss: 36.3334 - val_loss: 25.5445\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 20.49403\n",
      "Epoch 37/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 36.0118 - val_loss: 24.0755\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 20.49403\n",
      "Epoch 38/50\n",
      "10377/10377 [==============================] - 99s 10ms/step - loss: 34.2284 - val_loss: 38.5725\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 20.49403\n",
      "Epoch 39/50\n",
      "10377/10377 [==============================] - 103s 10ms/step - loss: 35.1277 - val_loss: 58.8946\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 20.49403\n",
      "Epoch 40/50\n",
      "10377/10377 [==============================] - 101s 10ms/step - loss: 35.5355 - val_loss: 27.5655\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 20.49403\n",
      "Epoch 41/50\n",
      "10377/10377 [==============================] - 101s 10ms/step - loss: 34.2336 - val_loss: 50.9288\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 20.49403\n",
      "Epoch 42/50\n",
      "10377/10377 [==============================] - 103s 10ms/step - loss: 33.9329 - val_loss: 24.0710\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 20.49403\n",
      "Epoch 43/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 34.7644 - val_loss: 25.7722\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 20.49403\n",
      "Epoch 44/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 33.0648 - val_loss: 20.9567\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 20.49403\n",
      "Epoch 45/50\n",
      "10377/10377 [==============================] - 99s 10ms/step - loss: 33.4329 - val_loss: 47.8090\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 20.49403\n",
      "Epoch 46/50\n",
      "10377/10377 [==============================] - 102s 10ms/step - loss: 32.9877 - val_loss: 33.6593\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 20.49403\n",
      "Epoch 47/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 32.2062 - val_loss: 21.3050\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 20.49403\n",
      "Epoch 48/50\n",
      "10377/10377 [==============================] - 99s 10ms/step - loss: 33.1035 - val_loss: 24.9491\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 20.49403\n",
      "Epoch 49/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 32.8189 - val_loss: 41.9274\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 20.49403\n",
      "Epoch 50/50\n",
      "10377/10377 [==============================] - 100s 10ms/step - loss: 31.0628 - val_loss: 51.3685\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 20.49403\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: prd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mfit(eeg_train, eeg_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(eeg_val, eeg_val), callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_callback])\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Load the best model saved by ModelCheckpoint\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m best_autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprd_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprd_loss\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Extract the encoder and decoder from the best autoencoder model\u001b[39;00m\n\u001b[1;32m     76\u001b[0m best_encoder \u001b[38;5;241m=\u001b[39m Model(best_autoencoder\u001b[38;5;241m.\u001b[39minput, best_autoencoder\u001b[38;5;241m.\u001b[39mget_layer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m load_context\u001b[38;5;241m.\u001b[39mload_context(options):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    205\u001b[0m       (\u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile) \u001b[38;5;129;01mor\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mis_hdf5(filepath))):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhdf5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m   filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, six\u001b[38;5;241m.\u001b[39mstring_types):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py:199\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    196\u001b[0m training_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(training_config\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Compile model.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43msaving_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_args_from_training_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    201\u001b[0m saving_utils\u001b[38;5;241m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Set optimizer weights.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saving_utils.py:218\u001b[0m, in \u001b[0;36mcompile_args_from_training_config\u001b[0;34m(training_config, custom_objects)\u001b[0m\n\u001b[1;32m    216\u001b[0m loss_config \u001b[38;5;241m=\u001b[39m training_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_nested_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Recover metrics.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/saving/saving_utils.py:259\u001b[0m, in \u001b[0;36m_deserialize_nested_config\u001b[0;34m(deserialize_fn, config)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_single_object(config):\n\u001b[0;32m--> 259\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    262\u001b[0m       k: _deserialize_nested_config(deserialize_fn, v)\n\u001b[1;32m    263\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    264\u001b[0m   }\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1854\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.losses.deserialize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Deserializes a serialized loss class/function instance.\u001b[39;00m\n\u001b[1;32m   1845\u001b[0m \n\u001b[1;32m   1846\u001b[0m \u001b[38;5;124;03m  Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;124;03m      A Keras `Loss` instance or a loss function.\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1854\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss function\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:377\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    375\u001b[0m   obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[1;32m    376\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m printable_module_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m object_name)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function: prd"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Conv1DTranspose, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the PRD loss function\n",
    "def prd(y_true, y_pred):\n",
    "    # Assuming the original data was in 16-bit signed integers\n",
    "    y_true = (y_true * (10743.3+10743.31)) - 10743.3\n",
    "    y_pred = (y_pred * (10743.3+10743.31)) - 10743.3\n",
    "\n",
    "    # Calculate the PRD (Percentage RMS Deviation)\n",
    "    nom = K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    denom = K.sqrt(K.mean(K.square(y_true)))\n",
    "    prd = (nom / denom) * 100.0\n",
    "    return prd\n",
    "\n",
    "# Define the input shape for single-channel EEG data with 64 samples\n",
    "input_shape = (64, 1)\n",
    "\n",
    "# Define the encoder\n",
    "input_layer = Input(shape=input_shape)\n",
    "x = Conv1D(16, kernel_size=3, activation='linear', padding='same')(input_layer)\n",
    "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "x = Conv1D(8, kernel_size=3, activation='linear', padding='same')(x)\n",
    "x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "x = Conv1D(8, kernel_size=3, activation='linear', padding='same')(x)\n",
    "encoded = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "\n",
    "# Flatten and bottleneck layer with 16 features\n",
    "x = Flatten()(x)\n",
    "bottleneck = Dense(16, activation='linear')(x)\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(input_layer, bottleneck, name=\"encoder\")\n",
    "\n",
    "# Define the decoder using Conv1DTranspose\n",
    "decoder_input = Input(shape=(16,))\n",
    "x = Dense(8 * 8, activation='linear')(decoder_input)  # Match the flattened dimension before upsampling\n",
    "x = Reshape((8, 8))(x)\n",
    "x = Conv1D(8, kernel_size=3, activation='linear', padding='same')(x)\n",
    "x = Conv1DTranspose(8, kernel_size=3, strides=2, activation='linear', padding='same')(x)\n",
    "x = Conv1D(8, kernel_size=3, activation='linear', padding='same')(x)\n",
    "x = Conv1DTranspose(8, kernel_size=3, strides=2, activation='linear', padding='same')(x)\n",
    "x = Conv1D(16, kernel_size=3, activation='linear', padding='same')(x)\n",
    "decoded = Conv1DTranspose(1, kernel_size=3, strides=2, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Decoder model\n",
    "decoder = Model(decoder_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Autoencoder model (combining encoder and decoder)\n",
    "autoencoder_input = input_layer\n",
    "autoencoder_output = decoder(encoder(autoencoder_input))\n",
    "autoencoder = Model(autoencoder_input, autoencoder_output, name=\"autoencoder\")\n",
    "autoencoder.compile(optimizer='adam', loss=prd)\n",
    "\n",
    "autoencoder.summary()\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.h5',  # Path to save the model\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='min',                # Mode: minimize the monitored metric\n",
    "    verbose=1                  # Print a message when saving the model\n",
    ")\n",
    "eeg_data = (fuller_data + 10743.3) / (10743.3+10743.31)  # Normalize to [0, 1]\n",
    "eeg_train, eeg_val = train_test_split(eeg_data, test_size=0.25, random_state=45)\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(eeg_train, eeg_train, epochs=50, batch_size=32, validation_data=(eeg_val, eeg_val), callbacks=[checkpoint_callback])\n",
    "\n",
    "# Load the best model saved by ModelCheckpoint\n",
    "best_autoencoder = load_model('best_model.keras', custom_objects={'prd': prd})\n",
    "\n",
    "# Extract the encoder and decoder from the best autoencoder model\n",
    "best_encoder = Model(best_autoencoder.input, best_autoencoder.get_layer('encoder').output)\n",
    "encoded_input = Input(shape=(16,))\n",
    "best_decoder = Model(encoded_input, best_autoencoder.layers[-1](best_autoencoder.layers[-2](encoded_input)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2.__internal__' has no attribute 'dispatch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QConv1D, QDense, QActivation, quantized_bits\n\u001b[1;32m      6\u001b[0m Qinput_ts \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_time_series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m QConv1D(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m             kernel_quantizer\u001b[38;5;241m=\u001b[39mquantized_bits(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m      9\u001b[0m             bias_quantizer\u001b[38;5;241m=\u001b[39mquantized_bits(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))(Qinput_ts)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/qkeras/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2t\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/qkeras/estimate.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputLayer\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QActivation\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QAdaptiveActivation\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QDense\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/qkeras/qlayers.py:58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_integer_bits\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_quantizer\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprunable_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrunableLayer\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_auto_range_constraint_initializer\u001b[39m(quantizer, constraint, initializer):\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Get value range automatically for quantizer.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m  Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m      initializer is initializer contraint by value range of quantizer.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow_model_optimization/__init__.py:86\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# To ensure users only access the expected public API, the API structure is\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# created in the `api` directory. Import all api modules.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/api/__init__.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparsity\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/api/sparsity/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Module containing code for sparsity.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/api/sparsity/keras/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Module containing sparsity code built on Keras abstractions.\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprune\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prune_low_magnitude\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprune\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prune_scope\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprune\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strip_pruning\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pruning_schedule \u001b[38;5;28;01mas\u001b[39;00m pruning_sched\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pruning_wrapper\n\u001b[1;32m     26\u001b[0m custom_object_scope \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcustom_object_scope\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprune_scope\u001b[39m():\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prunable_layer\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prune_registry\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pruning_impl\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparsity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pruning_schedule \u001b[38;5;28;01mas\u001b[39;00m pruning_sched\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune_registry.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,g-importing-member\u001b[39;00m\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,g-importing-member\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m   \u001b[38;5;66;03m# Internal case.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/keras/__internal__/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/keras/__internal__/backend/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/keras/src/__init__.py:21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/keras/src/applications/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/keras/src/applications/convnext.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/keras/src/backend.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_config\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_coordinator_utils \u001b[38;5;28;01mas\u001b[39;00m dc\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtensor_api \u001b[38;5;28;01mas\u001b[39;00m dtensor\n",
      "File \u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/keras/src/backend_config.py:33\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Default image data format, one of \"channels_last\", \"channels_first\".\u001b[39;00m\n\u001b[1;32m     29\u001b[0m _IMAGE_DATA_FORMAT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.backend.epsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mepsilon\u001b[39m():\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the value of the fuzz factor used in numeric expressions.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    1e-07\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _EPSILON\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2.__internal__' has no attribute 'dispatch'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from qkeras import QConv1D, QDense, QActivation, quantized_bits\n",
    "\n",
    "Qinput_ts = Input(shape=(64, 1), name=\"input_time_series\")\n",
    "x = QConv1D(16, 3, activation='linear', padding='same',\n",
    "            kernel_quantizer=quantized_bits(8, 0, 1),\n",
    "            bias_quantizer=quantized_bits(8, 0, 1))(Qinput_ts)\n",
    "x = QConv1D(8, 5, activation='linear', padding='same',\n",
    "            kernel_quantizer=quantized_bits(8, 0, 1),\n",
    "            bias_quantizer=quantized_bits(8, 0, 1))(x)\n",
    "x = QConv1D(8, 5, activation='linear', padding='same', strides=2,\n",
    "            kernel_quantizer=quantized_bits(8, 0, 1),\n",
    "            bias_quantizer=quantized_bits(8, 0, 1))(x)\n",
    "x = QConv1D(4, 5, activation='linear', padding='same', strides=2,\n",
    "            kernel_quantizer=quantized_bits(8, 0, 1),\n",
    "            bias_quantizer=quantized_bits(8, 0, 1))(x)\n",
    "x = Flatten()(x)\n",
    "Qencoded = QDense(16, activation='linear',\n",
    "                 kernel_quantizer=quantized_bits(8, 0, 1),\n",
    "                 bias_quantizer=quantized_bits(8, 0, 1))(x)\n",
    "\n",
    "quantized_encoder = Model(Qinput_ts, Qencoded, name=\"quantized_encoder\")\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input = keras.layers.Input(shape=(16,), name=\"encoded_input\") # 16\n",
    "x = keras.layers.Dense(16 * 4, activation='linear')(encoded_input) # 16 * 4\n",
    "x = keras.layers.Reshape((16, 4))(x) # Reshape back to (16, 4)\n",
    "x = keras.layers.Conv1DTranspose(8, 5, activation='linear', strides=2, padding='same')(x) # 16, 8\n",
    "x = keras.layers.Conv1DTranspose(16, 5, activation='linear', strides=2, padding='same')(x) # 32, 16\n",
    "x = keras.layers.Conv1DTranspose(8, 7, activation='linear', padding='same')(x) # 32, 16\n",
    "decoded = keras.layers.Conv1DTranspose(1, 3, activation='linear', padding='same')(x) # 64, 1\n",
    "\n",
    "decoder = keras.models.Model(encoded_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Define the autoencoder\n",
    "Qautoencoder_input = keras.layers.Input(shape=(64, 1), name=\"Qautoencoder_input\")\n",
    "Qencoded_ts = encoder(autoencoder_input)\n",
    "Qdecoded_ts = decoder(Qencoded_ts)\n",
    "\n",
    "Qautoencoder = keras.models.Model(Qautoencoder_input, Qdecoded_ts, name=\"Qautoencoder\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "Qautoencoder.compile(optimizer='adam', loss=prd_loss_dig2phy)\n",
    "\n",
    "# Summary of the autoencoder\n",
    "Qautoencoder.summary()\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model_quantised.h5',  # Path to save the model\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='min',                # Mode: minimize the monitored metric\n",
    "    verbose=1                  # Print a message when saving the model\n",
    ")\n",
    "# Train the autoencoder\n",
    "Qautoencoder.fit(train_data, train_data, epochs=30, batch_size=64, shuffle=True, validation_data=(val_data, val_data), callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " autoencoder_input (InputLa  [(None, 64, 1)]           0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                1580      \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 64, 1)             2841      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4421 (17.27 KB)\n",
      "Trainable params: 4421 (17.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 14:15:00.136808: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-06 14:15:02.203798: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-07-06 14:15:13.173990: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-06 14:15:19.494066: I external/local_xla/xla/service/service.cc:168] XLA service 0x45cc45e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-06 14:15:19.494132: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti, Compute Capability 7.5\n",
      "2024-07-06 14:15:19.525244: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720271719.658646   86237 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5535/5535 [==============================] - ETA: 0s - loss: 12.3590 - prd_loss_dig2phy: 24.6465\n",
      "Epoch 1: val_loss improved from inf to 9.73461, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 89s 12ms/step - loss: 12.3590 - prd_loss_dig2phy: 24.6465 - val_loss: 9.7346 - val_prd_loss_dig2phy: 20.4315\n",
      "Epoch 2/30\n",
      "5531/5535 [============================>.] - ETA: 0s - loss: 9.7702 - prd_loss_dig2phy: 20.4239\n",
      "Epoch 2: val_loss did not improve from 9.73461\n",
      "5535/5535 [==============================] - 62s 11ms/step - loss: 9.7703 - prd_loss_dig2phy: 20.4200 - val_loss: 9.8533 - val_prd_loss_dig2phy: 20.3880\n",
      "Epoch 3/30\n",
      "5533/5535 [============================>.] - ETA: 0s - loss: 9.6462 - prd_loss_dig2phy: 20.2003\n",
      "Epoch 3: val_loss did not improve from 9.73461\n",
      "5535/5535 [==============================] - 62s 11ms/step - loss: 9.6462 - prd_loss_dig2phy: 20.2038 - val_loss: 10.9344 - val_prd_loss_dig2phy: 21.5852\n",
      "Epoch 4/30\n",
      "5532/5535 [============================>.] - ETA: 0s - loss: 9.6047 - prd_loss_dig2phy: 20.1641\n",
      "Epoch 4: val_loss improved from 9.73461 to 9.39106, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 61s 11ms/step - loss: 9.6041 - prd_loss_dig2phy: 20.1614 - val_loss: 9.3911 - val_prd_loss_dig2phy: 19.7935\n",
      "Epoch 5/30\n",
      "5531/5535 [============================>.] - ETA: 0s - loss: 9.5662 - prd_loss_dig2phy: 20.1850\n",
      "Epoch 5: val_loss did not improve from 9.39106\n",
      "5535/5535 [==============================] - 63s 11ms/step - loss: 9.5661 - prd_loss_dig2phy: 20.1873 - val_loss: 9.4698 - val_prd_loss_dig2phy: 19.9259\n",
      "Epoch 6/30\n",
      "5535/5535 [==============================] - ETA: 0s - loss: 9.5231 - prd_loss_dig2phy: 20.0357\n",
      "Epoch 6: val_loss improved from 9.39106 to 9.37122, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 60s 11ms/step - loss: 9.5231 - prd_loss_dig2phy: 20.0357 - val_loss: 9.3712 - val_prd_loss_dig2phy: 19.8053\n",
      "Epoch 7/30\n",
      "5531/5535 [============================>.] - ETA: 0s - loss: 9.5062 - prd_loss_dig2phy: 20.0385\n",
      "Epoch 7: val_loss improved from 9.37122 to 9.26407, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 59s 11ms/step - loss: 9.5047 - prd_loss_dig2phy: 20.0339 - val_loss: 9.2641 - val_prd_loss_dig2phy: 19.6565\n",
      "Epoch 8/30\n",
      "5535/5535 [==============================] - ETA: 0s - loss: 9.4918 - prd_loss_dig2phy: 20.0191\n",
      "Epoch 8: val_loss did not improve from 9.26407\n",
      "5535/5535 [==============================] - 61s 11ms/step - loss: 9.4918 - prd_loss_dig2phy: 20.0191 - val_loss: 9.4021 - val_prd_loss_dig2phy: 19.7831\n",
      "Epoch 9/30\n",
      "5530/5535 [============================>.] - ETA: 0s - loss: 9.4753 - prd_loss_dig2phy: 19.9567\n",
      "Epoch 9: val_loss did not improve from 9.26407\n",
      "5535/5535 [==============================] - 59s 11ms/step - loss: 9.4736 - prd_loss_dig2phy: 19.9559 - val_loss: 9.4574 - val_prd_loss_dig2phy: 19.8628\n",
      "Epoch 10/30\n",
      "5535/5535 [==============================] - ETA: 0s - loss: 9.4381 - prd_loss_dig2phy: 20.0068\n",
      "Epoch 10: val_loss improved from 9.26407 to 9.21063, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 60s 11ms/step - loss: 9.4381 - prd_loss_dig2phy: 20.0068 - val_loss: 9.2106 - val_prd_loss_dig2phy: 19.6274\n",
      "Epoch 11/30\n",
      "5534/5535 [============================>.] - ETA: 0s - loss: 9.4316 - prd_loss_dig2phy: 19.9606\n",
      "Epoch 11: val_loss did not improve from 9.21063\n",
      "5535/5535 [==============================] - 59s 11ms/step - loss: 9.4315 - prd_loss_dig2phy: 19.9608 - val_loss: 9.3207 - val_prd_loss_dig2phy: 19.6843\n",
      "Epoch 12/30\n",
      "5532/5535 [============================>.] - ETA: 0s - loss: 9.4315 - prd_loss_dig2phy: 19.9075\n",
      "Epoch 12: val_loss did not improve from 9.21063\n",
      "5535/5535 [==============================] - 61s 11ms/step - loss: 9.4313 - prd_loss_dig2phy: 19.9073 - val_loss: 9.2519 - val_prd_loss_dig2phy: 19.7327\n",
      "Epoch 13/30\n",
      "5535/5535 [==============================] - ETA: 0s - loss: 9.4158 - prd_loss_dig2phy: 19.8635\n",
      "Epoch 13: val_loss did not improve from 9.21063\n",
      "5535/5535 [==============================] - 57s 10ms/step - loss: 9.4158 - prd_loss_dig2phy: 19.8635 - val_loss: 9.6242 - val_prd_loss_dig2phy: 20.0998\n",
      "Epoch 14/30\n",
      "5531/5535 [============================>.] - ETA: 0s - loss: 9.4112 - prd_loss_dig2phy: 19.9249\n",
      "Epoch 14: val_loss did not improve from 9.21063\n",
      "5535/5535 [==============================] - 61s 11ms/step - loss: 9.4106 - prd_loss_dig2phy: 19.9251 - val_loss: 9.2468 - val_prd_loss_dig2phy: 19.6063\n",
      "Epoch 15/30\n",
      "5535/5535 [==============================] - ETA: 0s - loss: 9.3939 - prd_loss_dig2phy: 19.8123\n",
      "Epoch 15: val_loss did not improve from 9.21063\n",
      "5535/5535 [==============================] - 59s 11ms/step - loss: 9.3939 - prd_loss_dig2phy: 19.8123 - val_loss: 9.3101 - val_prd_loss_dig2phy: 19.8043\n",
      "Epoch 16/30\n",
      "5532/5535 [============================>.] - ETA: 0s - loss: 9.4024 - prd_loss_dig2phy: 19.9387\n",
      "Epoch 16: val_loss improved from 9.21063 to 9.20943, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 59s 11ms/step - loss: 9.4022 - prd_loss_dig2phy: 19.9369 - val_loss: 9.2094 - val_prd_loss_dig2phy: 19.6050\n",
      "Epoch 17/30\n",
      "5531/5535 [============================>.] - ETA: 0s - loss: 9.3799 - prd_loss_dig2phy: 19.9679\n",
      "Epoch 17: val_loss improved from 9.20943 to 9.20835, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 68s 12ms/step - loss: 9.3802 - prd_loss_dig2phy: 19.9702 - val_loss: 9.2083 - val_prd_loss_dig2phy: 19.6165\n",
      "Epoch 18/30\n",
      "5534/5535 [============================>.] - ETA: 0s - loss: 9.3850 - prd_loss_dig2phy: 19.9536\n",
      "Epoch 18: val_loss did not improve from 9.20835\n",
      "5535/5535 [==============================] - 58s 11ms/step - loss: 9.3850 - prd_loss_dig2phy: 19.9524 - val_loss: 9.3191 - val_prd_loss_dig2phy: 19.6709\n",
      "Epoch 19/30\n",
      "5534/5535 [============================>.] - ETA: 0s - loss: 9.3893 - prd_loss_dig2phy: 19.8475\n",
      "Epoch 19: val_loss improved from 9.20835 to 9.20599, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 63s 11ms/step - loss: 9.3892 - prd_loss_dig2phy: 19.8469 - val_loss: 9.2060 - val_prd_loss_dig2phy: 19.6274\n",
      "Epoch 20/30\n",
      "5531/5535 [============================>.] - ETA: 0s - loss: 9.3774 - prd_loss_dig2phy: 19.9345\n",
      "Epoch 20: val_loss did not improve from 9.20599\n",
      "5535/5535 [==============================] - 63s 11ms/step - loss: 9.3768 - prd_loss_dig2phy: 19.9298 - val_loss: 9.2144 - val_prd_loss_dig2phy: 19.6586\n",
      "Epoch 21/30\n",
      "5534/5535 [============================>.] - ETA: 0s - loss: 9.3700 - prd_loss_dig2phy: 19.8952\n",
      "Epoch 21: val_loss improved from 9.20599 to 9.19838, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 63s 11ms/step - loss: 9.3698 - prd_loss_dig2phy: 19.8955 - val_loss: 9.1984 - val_prd_loss_dig2phy: 19.5771\n",
      "Epoch 22/30\n",
      "5534/5535 [============================>.] - ETA: 0s - loss: 9.3698 - prd_loss_dig2phy: 19.8702\n",
      "Epoch 22: val_loss did not improve from 9.19838\n",
      "5535/5535 [==============================] - 62s 11ms/step - loss: 9.3703 - prd_loss_dig2phy: 19.8705 - val_loss: 9.3134 - val_prd_loss_dig2phy: 19.7682\n",
      "Epoch 23/30\n",
      "5534/5535 [============================>.] - ETA: 0s - loss: 9.3624 - prd_loss_dig2phy: 19.9116\n",
      "Epoch 23: val_loss improved from 9.19838 to 9.18137, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 61s 11ms/step - loss: 9.3622 - prd_loss_dig2phy: 19.9106 - val_loss: 9.1814 - val_prd_loss_dig2phy: 19.5891\n",
      "Epoch 24/30\n",
      "5532/5535 [============================>.] - ETA: 0s - loss: 9.3598 - prd_loss_dig2phy: 19.9508\n",
      "Epoch 24: val_loss did not improve from 9.18137\n",
      "5535/5535 [==============================] - 58s 11ms/step - loss: 9.3593 - prd_loss_dig2phy: 19.9503 - val_loss: 9.2834 - val_prd_loss_dig2phy: 19.7188\n",
      "Epoch 25/30\n",
      "5533/5535 [============================>.] - ETA: 0s - loss: 9.3500 - prd_loss_dig2phy: 19.8811\n",
      "Epoch 25: val_loss improved from 9.18137 to 9.17803, saving model to mae_model.keras\n",
      "5535/5535 [==============================] - 57s 10ms/step - loss: 9.3496 - prd_loss_dig2phy: 19.8806 - val_loss: 9.1780 - val_prd_loss_dig2phy: 19.5749\n",
      "Epoch 26/30\n",
      "5535/5535 [==============================] - ETA: 0s - loss: 9.3549 - prd_loss_dig2phy: 19.8279\n",
      "Epoch 26: val_loss did not improve from 9.17803\n",
      "5535/5535 [==============================] - 59s 11ms/step - loss: 9.3549 - prd_loss_dig2phy: 19.8279 - val_loss: 9.2312 - val_prd_loss_dig2phy: 19.6134\n",
      "Epoch 27/30\n",
      "5535/5535 [==============================] - ETA: 0s - loss: 9.3466 - prd_loss_dig2phy: 19.8886\n",
      "Epoch 27: val_loss did not improve from 9.17803\n",
      "5535/5535 [==============================] - 60s 11ms/step - loss: 9.3466 - prd_loss_dig2phy: 19.8886 - val_loss: 9.2811 - val_prd_loss_dig2phy: 19.7814\n",
      "Epoch 28/30\n",
      "5533/5535 [============================>.] - ETA: 0s - loss: 9.3462 - prd_loss_dig2phy: 19.7828\n",
      "Epoch 28: val_loss did not improve from 9.17803\n",
      "5535/5535 [==============================] - 58s 10ms/step - loss: 9.3469 - prd_loss_dig2phy: 19.7851 - val_loss: 9.2544 - val_prd_loss_dig2phy: 19.6507\n",
      "Epoch 29/30\n",
      "5530/5535 [============================>.] - ETA: 0s - loss: 9.3476 - prd_loss_dig2phy: 19.8537\n",
      "Epoch 29: val_loss did not improve from 9.17803\n",
      "5535/5535 [==============================] - 59s 11ms/step - loss: 9.3472 - prd_loss_dig2phy: 19.8562 - val_loss: 9.2011 - val_prd_loss_dig2phy: 19.6192\n",
      "Epoch 30/30\n",
      "5531/5535 [============================>.] - ETA: 0s - loss: 9.3489 - prd_loss_dig2phy: 19.8318\n",
      "Epoch 30: val_loss did not improve from 9.17803\n",
      "5535/5535 [==============================] - 58s 10ms/step - loss: 9.3478 - prd_loss_dig2phy: 19.8304 - val_loss: 9.2309 - val_prd_loss_dig2phy: 19.6734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7b8993f190>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the encoder\n",
    "input_ts = keras.layers.Input(shape=(64, 1), name=\"input_time_series\") # 64, 1\n",
    "x = keras.layers.Conv1D(16, 3, activation='linear', padding='same')(input_ts) # 64, 16\n",
    "x = keras.layers.Conv1D(8, 5, activation='linear', padding='same')(input_ts) # 64, 16\n",
    "x = keras.layers.Conv1D(8, 5, activation='linear', padding='same', strides=2)(x) # 32, 8\n",
    "x = keras.layers.Conv1D(4, 5, activation='linear', padding='same', strides=2)(x) # 16, 4\n",
    "x = keras.layers.Flatten()(x) # Flatten for Dense layer\n",
    "encoded = keras.layers.Dense(16, activation='linear')(x) # 16\n",
    "encoder = keras.models.Model(input_ts, encoded, name=\"encoder\")\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input = keras.layers.Input(shape=(16,), name=\"encoded_input\") # 16\n",
    "x = keras.layers.Dense(16 * 4, activation='linear')(encoded_input) # 16 * 4\n",
    "x = keras.layers.Reshape((16, 4))(x) # Reshape back to (16, 4)\n",
    "x = keras.layers.Conv1DTranspose(8, 5, activation='linear', strides=2, padding='same')(x) # 16, 8\n",
    "x = keras.layers.Conv1DTranspose(16, 5, activation='linear', strides=2, padding='same')(x) # 32, 16\n",
    "x = keras.layers.Conv1DTranspose(8, 7, activation='linear', padding='same')(x) # 32, 16\n",
    "decoded = keras.layers.Conv1DTranspose(1, 3, activation='linear', padding='same')(x) # 64, 1\n",
    "\n",
    "decoder = keras.models.Model(encoded_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Define the autoencoder\n",
    "autoencoder_input = keras.layers.Input(shape=(64, 1), name=\"autoencoder_input\")\n",
    "encoded_ts = encoder(autoencoder_input)\n",
    "decoded_ts = decoder(encoded_ts)\n",
    "\n",
    "autoencoder = keras.models.Model(autoencoder_input, decoded_ts, name=\"autoencoder\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mae', metrics=[prd_loss_dig2phy])\n",
    "\n",
    "# Summary of the autoencoder\n",
    "autoencoder.summary()\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='mae_model.keras',  # Path to save the model\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='min',                # Mode: minimize the monitored metric\n",
    "    verbose=1                  # Print a message when saving the model\n",
    ")\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(train_data, train_data, epochs=30, batch_size=64, shuffle=True, validation_data=(val_data, val_data), callbacks=[checkpoint_callback])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "best_autoencoder = keras.saving.load_model('best_model.h5', custom_objects={'prd_loss_dig2phy': prd_loss_dig2phy})\n",
    "best_encoder= best_autoencoder.layers[1]\n",
    "best_encoder.summary()\n",
    "#best_encoder.save('extracted_encoder_model.h5')\n",
    "pred = best_encoder.predict(val_data)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-46.49892    22.105198  -40.036846   45.483715    9.410024   -2.7631993\n",
      " -65.50559    18.255516  -44.084755  -16.793797  -43.908184  -13.758628\n",
      "  -7.714551    9.876102   -3.8334224  -5.4138165]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "autoencoder_input (InputLaye [(None, 64, 1)]           0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 16)                2172      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 64, 1)             2585      \n",
      "=================================================================\n",
      "Total params: 4,757\n",
      "Trainable params: 4,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "11069/11069 [==============================] - 119s 9ms/step - loss: 27.4131 - val_loss: 19.1245\n",
      "Epoch 2/30\n",
      "11069/11069 [==============================] - 104s 9ms/step - loss: 19.3009 - val_loss: 19.0637\n",
      "Epoch 3/30\n",
      "11069/11069 [==============================] - 102s 9ms/step - loss: 19.3709 - val_loss: 19.0377\n",
      "Epoch 4/30\n",
      "11069/11069 [==============================] - 97s 9ms/step - loss: 19.0109 - val_loss: 18.8186\n",
      "Epoch 5/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 18.9375 - val_loss: 18.9508\n",
      "Epoch 6/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 18.8882 - val_loss: 18.7563\n",
      "Epoch 7/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 19.0239 - val_loss: 18.7765\n",
      "Epoch 8/30\n",
      "11069/11069 [==============================] - 103s 9ms/step - loss: 18.9961 - val_loss: 18.7928\n",
      "Epoch 9/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 18.9681 - val_loss: 18.8161\n",
      "Epoch 10/30\n",
      "11069/11069 [==============================] - 99s 9ms/step - loss: 18.9929 - val_loss: 18.7241\n",
      "Epoch 11/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 18.8593 - val_loss: 18.7270\n",
      "Epoch 12/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 19.1227 - val_loss: 18.7169\n",
      "Epoch 13/30\n",
      "11069/11069 [==============================] - 98s 9ms/step - loss: 19.1116 - val_loss: 18.8516\n",
      "Epoch 14/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 18.8517 - val_loss: 18.7270\n",
      "Epoch 15/30\n",
      "11069/11069 [==============================] - 99s 9ms/step - loss: 18.8759 - val_loss: 18.7493\n",
      "Epoch 16/30\n",
      "11069/11069 [==============================] - 98s 9ms/step - loss: 19.0254 - val_loss: 18.7237\n",
      "Epoch 17/30\n",
      "11069/11069 [==============================] - 99s 9ms/step - loss: 18.7308 - val_loss: 18.7107\n",
      "Epoch 18/30\n",
      "11069/11069 [==============================] - 97s 9ms/step - loss: 18.9924 - val_loss: 18.7082\n",
      "Epoch 19/30\n",
      "11069/11069 [==============================] - 98s 9ms/step - loss: 18.9446 - val_loss: 18.7507\n",
      "Epoch 20/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 18.9870 - val_loss: 18.7645\n",
      "Epoch 21/30\n",
      "11069/11069 [==============================] - 95s 9ms/step - loss: 18.7885 - val_loss: 18.7070\n",
      "Epoch 22/30\n",
      "11069/11069 [==============================] - 99s 9ms/step - loss: 18.7133 - val_loss: 18.7168\n",
      "Epoch 23/30\n",
      "11069/11069 [==============================] - 99s 9ms/step - loss: 18.8286 - val_loss: 18.7539\n",
      "Epoch 24/30\n",
      "11069/11069 [==============================] - 99s 9ms/step - loss: 18.8844 - val_loss: 18.7189\n",
      "Epoch 25/30\n",
      "11069/11069 [==============================] - 98s 9ms/step - loss: 18.9219 - val_loss: 18.7250\n",
      "Epoch 26/30\n",
      "11069/11069 [==============================] - 99s 9ms/step - loss: 19.0173 - val_loss: 18.7649\n",
      "Epoch 27/30\n",
      "11069/11069 [==============================] - 96s 9ms/step - loss: 18.9500 - val_loss: 18.7260\n",
      "Epoch 28/30\n",
      "11069/11069 [==============================] - 101s 9ms/step - loss: 18.8296 - val_loss: 18.7042\n",
      "Epoch 29/30\n",
      "11069/11069 [==============================] - 100s 9ms/step - loss: 18.7055 - val_loss: 18.7691\n",
      "Epoch 30/30\n",
      "11069/11069 [==============================] - 98s 9ms/step - loss: 18.8680 - val_loss: 18.7323\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# Define the encoder\n",
    "input_ts = keras.layers.Input(shape=(64, 1), name=\"input_time_series\") # 64, 1\n",
    "x = keras.layers.Conv1D(16, 3, activation='linear', padding='same')(input_ts) # 64, 16\n",
    "x = keras.layers.Conv1D(8, 7, activation='linear', padding='same')(x) # 32, 8\n",
    "x = keras.layers.MaxPooling1D(2, padding='same')(x)  # 16, 8\n",
    "x = keras.layers.Conv1D(4, 5, activation='linear', padding='same')(x) # 16, 4\n",
    "x = keras.layers.MaxPooling1D(2, padding='same')(x)  # 32, 16\n",
    "x = keras.layers.Flatten()(x) # Flatten for Dense layer\n",
    "encoded = keras.layers.Dense(16, activation='linear')(x) # 8\n",
    "encoder = keras.models.Model(input_ts, encoded, name=\"encoder\")\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input = keras.layers.Input(shape=(16,), name=\"encoded_input\") # 8\n",
    "x = keras.layers.Dense(16 * 4, activation='linear')(encoded_input) # 16 * 4\n",
    "x = keras.layers.Reshape((16, 4))(x) # Reshape back to (16, 4)\n",
    "x = keras.layers.Conv1D(8, 5, activation='linear', padding='same')(x) # 16, 8\n",
    "x = keras.layers.UpSampling1D(2)(x)  # 32, 8\n",
    "x = keras.layers.Conv1D(16, 5, activation='linear', padding='same')(x) # 32, 16\n",
    "x = keras.layers.UpSampling1D(2)(x)  # 64, 16\n",
    "x = keras.layers.Conv1D(8, 5, activation='linear', padding='same')(x) # 32, 16\n",
    "decoded = keras.layers.Conv1D(1, 3, activation='linear', padding='same')(x) # 64, 1\n",
    "\n",
    "decoder = keras.models.Model(encoded_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Define the autoencoder\n",
    "autoencoder_input = keras.layers.Input(shape=(64, 1), name=\"autoencoder_input\")\n",
    "encoded_ts = encoder(autoencoder_input)\n",
    "decoded_ts = decoder(encoded_ts)\n",
    "\n",
    "autoencoder = keras.models.Model(autoencoder_input, decoded_ts, name=\"autoencoder\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss=prd_loss_dig2phy)\n",
    "\n",
    "# Summary of the autoencoder\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(train_data, train_data, epochs=30, batch_size=32, shuffle=True, validation_data=(val_data, val_data))\n",
    "\n",
    "# Save the encoder and decoder\n",
    "encoder.save(\"encoder_model.h5\")\n",
    "decoder.save(\"decoder_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 12-bit Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_mae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "autoencoder_mae_input (Input [(None, 64, 1)]           0         \n",
      "_________________________________________________________________\n",
      "encoder_mae (Functional)     (None, 16)                1916      \n",
      "_________________________________________________________________\n",
      "decoder_mae (Functional)     (None, 64, 1)             2425      \n",
      "=================================================================\n",
      "Total params: 4,341\n",
      "Trainable params: 4,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "6227/6227 [==============================] - 59s 9ms/step - loss: 146.2536 - mae: 112.2447 - val_loss: 40.5526 - val_mae: 23.0098\n",
      "Epoch 2/20\n",
      "6227/6227 [==============================] - 66s 11ms/step - loss: 49.1783 - mae: 33.6047 - val_loss: 42.2959 - val_mae: 28.7501\n",
      "Epoch 3/20\n",
      "6227/6227 [==============================] - 64s 10ms/step - loss: 42.5687 - mae: 28.2866 - val_loss: 37.8455 - val_mae: 25.1271\n",
      "Epoch 4/20\n",
      "6227/6227 [==============================] - 61s 10ms/step - loss: 41.6675 - mae: 28.7623 - val_loss: 59.7701 - val_mae: 51.8876\n",
      "Epoch 5/20\n",
      "6227/6227 [==============================] - 66s 11ms/step - loss: 39.4827 - mae: 26.5292 - val_loss: 33.7279 - val_mae: 21.5431\n",
      "Epoch 6/20\n",
      "6227/6227 [==============================] - 60s 10ms/step - loss: 35.2846 - mae: 22.8683 - val_loss: 74.8199 - val_mae: 62.5192\n",
      "Epoch 7/20\n",
      "6227/6227 [==============================] - 66s 11ms/step - loss: 35.5478 - mae: 23.1777 - val_loss: 29.1947 - val_mae: 15.9020\n",
      "Epoch 8/20\n",
      "6227/6227 [==============================] - 60s 10ms/step - loss: 33.6780 - mae: 21.6750 - val_loss: 38.9793 - val_mae: 30.1632\n",
      "Epoch 9/20\n",
      "6227/6227 [==============================] - 64s 10ms/step - loss: 34.2474 - mae: 22.8106 - val_loss: 30.5254 - val_mae: 18.7676\n",
      "Epoch 10/20\n",
      "6227/6227 [==============================] - 62s 10ms/step - loss: 33.3216 - mae: 22.0613 - val_loss: 51.4506 - val_mae: 44.4991\n",
      "Epoch 11/20\n",
      "6227/6227 [==============================] - 62s 10ms/step - loss: 34.0301 - mae: 22.4975 - val_loss: 45.1414 - val_mae: 38.3692\n",
      "Epoch 12/20\n",
      "6227/6227 [==============================] - 64s 10ms/step - loss: 33.2460 - mae: 21.8791 - val_loss: 51.6894 - val_mae: 45.8240\n",
      "Epoch 13/20\n",
      "6227/6227 [==============================] - 61s 10ms/step - loss: 32.3734 - mae: 21.2859 - val_loss: 33.1880 - val_mae: 23.2285\n",
      "Epoch 14/20\n",
      "6227/6227 [==============================] - 64s 10ms/step - loss: 31.8448 - mae: 20.4173 - val_loss: 29.5493 - val_mae: 17.6750\n",
      "Epoch 15/20\n",
      "6227/6227 [==============================] - 61s 10ms/step - loss: 31.1890 - mae: 19.6817 - val_loss: 30.2600 - val_mae: 19.5322\n",
      "Epoch 16/20\n",
      "6227/6227 [==============================] - 66s 11ms/step - loss: 30.9079 - mae: 19.0255 - val_loss: 41.4164 - val_mae: 34.2178\n",
      "Epoch 17/20\n",
      "6227/6227 [==============================] - 60s 10ms/step - loss: 32.6373 - mae: 21.5119 - val_loss: 28.2733 - val_mae: 15.9915\n",
      "Epoch 18/20\n",
      "6227/6227 [==============================] - 66s 11ms/step - loss: 31.1353 - mae: 19.9608 - val_loss: 28.4727 - val_mae: 16.3187\n",
      "Epoch 19/20\n",
      "6227/6227 [==============================] - 60s 10ms/step - loss: 29.7495 - mae: 18.0602 - val_loss: 38.7836 - val_mae: 27.0299\n",
      "Epoch 20/20\n",
      "6227/6227 [==============================] - 64s 10ms/step - loss: 32.2217 - mae: 20.8714 - val_loss: 28.2928 - val_mae: 16.5742\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the encoder\n",
    "input_ts1 = keras.layers.Input(shape=(64, 1), name=\"input_time_series\") # 64, 1\n",
    "x = keras.layers.Conv1D(16, 3, activation='relu', padding='same')(input_ts1) # 64, 16\n",
    "x = keras.layers.MaxPooling1D(2, padding='same')(x)  # 32, 16\n",
    "x = keras.layers.Conv1D(8, 5, activation='relu', padding='same')(x) # 32, 8\n",
    "x = keras.layers.MaxPooling1D(2, padding='same')(x)  # 16, 8\n",
    "x = keras.layers.Conv1D(4, 5, activation='relu', padding='same')(x) # 16, 4\n",
    "x = keras.layers.Flatten()(x) # Flatten for Dense layer\n",
    "encoded1 = keras.layers.Dense(16, activation='relu')(x) # 8\n",
    "encoder1 = keras.models.Model(input_ts1, encoded1, name=\"encoder_mae\")\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input1 = keras.layers.Input(shape=(16,), name=\"encoded_input\") # 8\n",
    "x = keras.layers.Dense(16 * 4, activation='relu')(encoded_input1) # 16 * 4\n",
    "x = keras.layers.Reshape((16, 4))(x) # Reshape back to (16, 4)\n",
    "x = keras.layers.Conv1D(8, 3, activation='relu', padding='same')(x) # 16, 8\n",
    "x = keras.layers.UpSampling1D(2)(x)  # 32, 8\n",
    "x = keras.layers.Conv1D(16, 3, activation='relu', padding='same')(x) # 32, 16\n",
    "x = keras.layers.UpSampling1D(2)(x)  # 64, 16\n",
    "x = keras.layers.Conv1D(16, 3, activation='relu', padding='same')(x) # 32, 16\n",
    "decoded1 = keras.layers.Conv1D(1, 3, activation='linear', padding='same')(x) # 64, 1\n",
    "\n",
    "decoder1 = keras.models.Model(encoded_input1, decoded1, name=\"decoder_mae\")\n",
    "\n",
    "# Define the autoencoder\n",
    "autoencoder_input1 = keras.layers.Input(shape=(64, 1), name=\"autoencoder_mae_input\")\n",
    "encoded_ts1 = encoder1(autoencoder_input1)\n",
    "decoded_ts1 = decoder1(encoded_ts1)\n",
    "\n",
    "autoencoder1 = keras.models.Model(autoencoder_input1, decoded_ts1, name=\"autoencoder_mae\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder1.compile(optimizer='adam', loss=prd_dig2phy1, metrics=['mae'])\n",
    "\n",
    "# Summary of the autoencoder\n",
    "autoencoder1.summary()\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder1.fit(clipped_data, train_data, epochs=20, batch_size=64, shuffle=True, validation_data = (val_data, val_data))\n",
    "\n",
    "# Save the encoder and decoder\n",
    "encoder1.save(\"encoder_model.h5\")\n",
    "decoder1.save(\"decoder_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "autoencoder_input (InputLaye [(None, 128, 1)]          0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 32)                2382      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 128, 1)            5681      \n",
      "=================================================================\n",
      "Total params: 8,063\n",
      "Trainable params: 8,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2629/2629 [==============================] - 45s 14ms/step - loss: 41.4319 - mse: 17003.9249 - val_loss: 23.9802 - val_mse: 5727.9746\n",
      "Epoch 2/20\n",
      "2629/2629 [==============================] - 28s 10ms/step - loss: 22.8879 - mse: 5480.8669 - val_loss: 20.7628 - val_mse: 4367.6260\n",
      "Epoch 3/20\n",
      "2629/2629 [==============================] - 31s 12ms/step - loss: 20.4841 - mse: 4736.8497 - val_loss: 19.5748 - val_mse: 3884.4150\n",
      "Epoch 4/20\n",
      "2629/2629 [==============================] - 31s 12ms/step - loss: 19.9197 - mse: 4524.4944 - val_loss: 19.9358 - val_mse: 3929.1924\n",
      "Epoch 5/20\n",
      "2629/2629 [==============================] - 33s 12ms/step - loss: 19.7122 - mse: 4295.5906 - val_loss: 19.3696 - val_mse: 3768.9731\n",
      "Epoch 6/20\n",
      "2629/2629 [==============================] - 30s 11ms/step - loss: 19.6630 - mse: 4202.9435 - val_loss: 19.3781 - val_mse: 3757.9670\n",
      "Epoch 7/20\n",
      "2629/2629 [==============================] - 29s 11ms/step - loss: 19.6995 - mse: 4229.2464 - val_loss: 19.2291 - val_mse: 3740.7195\n",
      "Epoch 8/20\n",
      "2629/2629 [==============================] - 30s 11ms/step - loss: 19.2221 - mse: 4413.6322 - val_loss: 19.3869 - val_mse: 3763.8513\n",
      "Epoch 9/20\n",
      "2629/2629 [==============================] - 30s 11ms/step - loss: 19.6694 - mse: 4746.1023 - val_loss: 19.2536 - val_mse: 3725.9126\n",
      "Epoch 10/20\n",
      "2629/2629 [==============================] - 33s 13ms/step - loss: 19.1676 - mse: 3926.6191 - val_loss: 19.2280 - val_mse: 3695.4954\n",
      "Epoch 11/20\n",
      "2629/2629 [==============================] - 31s 12ms/step - loss: 19.3964 - mse: 3980.8025 - val_loss: 19.2227 - val_mse: 3683.6804\n",
      "Epoch 12/20\n",
      "2629/2629 [==============================] - 28s 11ms/step - loss: 19.2764 - mse: 4099.5742 - val_loss: 19.7285 - val_mse: 3794.1919\n",
      "Epoch 13/20\n",
      "2629/2629 [==============================] - 28s 10ms/step - loss: 19.4578 - mse: 3772.4996 - val_loss: 19.1263 - val_mse: 3654.7454\n",
      "Epoch 14/20\n",
      "2629/2629 [==============================] - 29s 11ms/step - loss: 19.4220 - mse: 4045.8751 - val_loss: 19.1003 - val_mse: 3657.9216\n",
      "Epoch 15/20\n",
      "2629/2629 [==============================] - 31s 12ms/step - loss: 19.4948 - mse: 3541.0924 - val_loss: 19.1057 - val_mse: 3653.0205\n",
      "Epoch 16/20\n",
      "2629/2629 [==============================] - 32s 12ms/step - loss: 18.9923 - mse: 3537.4360 - val_loss: 19.2283 - val_mse: 3655.6658\n",
      "Epoch 17/20\n",
      "2629/2629 [==============================] - 29s 11ms/step - loss: 19.2820 - mse: 3527.1495 - val_loss: 19.2548 - val_mse: 3687.6448\n",
      "Epoch 18/20\n",
      "2629/2629 [==============================] - 29s 11ms/step - loss: 19.2956 - mse: 3261.7992 - val_loss: 18.9797 - val_mse: 3693.4280\n",
      "Epoch 19/20\n",
      "2629/2629 [==============================] - 28s 11ms/step - loss: 18.6272 - mse: 4256.5078 - val_loss: 17.5289 - val_mse: 3898.9409\n",
      "Epoch 20/20\n",
      "2629/2629 [==============================] - 30s 11ms/step - loss: 17.6929 - mse: 4401.9080 - val_loss: 17.3381 - val_mse: 3889.0674\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the encoder\n",
    "input_ts = keras.layers.Input(shape=(128, 1), name=\"input_time_series\") # 128, 1\n",
    "x = keras.layers.Conv1D(8, 3, activation='linear', padding='same')(input_ts) # 128, 16\n",
    "x = keras.layers.MaxPooling1D(2, padding='same')(x)  # 64, 16\n",
    "x = keras.layers.Conv1D(4, 7, activation='linear', padding='same')(x) # 64, 8\n",
    "x = keras.layers.MaxPooling1D(2, padding='same')(x)  # 32, 8\n",
    "x = keras.layers.Conv1D(2, 5, activation='linear', padding='same')(x) # 32, 4\n",
    "x = keras.layers.Flatten()(x) # Flatten for Dense layer\n",
    "encoded = keras.layers.Dense(32, activation='linear')(x) # 16\n",
    "encoder = keras.models.Model(input_ts, encoded, name=\"encoder\")\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input = keras.layers.Input(shape=(32,), name=\"encoded_input\") # 16\n",
    "x = keras.layers.Dense(32 * 4, activation='linear')(encoded_input) # 32 * 4\n",
    "x = keras.layers.Reshape((32, 4))(x) # Reshape back to (32, 4)\n",
    "x = keras.layers.Conv1D(8, 5, activation='linear', padding='same')(x) # 32, 8\n",
    "x = keras.layers.UpSampling1D(2)(x)  # 64, 8\n",
    "x = keras.layers.Conv1D(8, 5, activation='linear', padding='same')(x) # 64, 16\n",
    "x = keras.layers.UpSampling1D(2)(x)  # 128, 16\n",
    "x = keras.layers.Conv1D(16, 7, activation='linear', padding='same')(x) # 64, 16\n",
    "decoded = keras.layers.Conv1D(1, 3, activation='linear', padding='same')(x) # 128, 1\n",
    "\n",
    "decoder = keras.models.Model(encoded_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Define the autoencoder\n",
    "autoencoder_input = keras.layers.Input(shape=(128, 1), name=\"autoencoder_input\")\n",
    "encoded_ts = encoder(autoencoder_input)\n",
    "decoded_ts = decoder(encoded_ts)\n",
    "\n",
    "autoencoder = keras.models.Model(autoencoder_input, decoded_ts, name=\"autoencoder\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss=prd_loss_dig2phy, metrics=['mse'])\n",
    "\n",
    "# Summary of the autoencoder\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoencoder.fit(train_data, train_data, epochs=20, batch_size=64, shuffle=True, validation_split=0.2)\n",
    "\n",
    "# Save the encoder and decoder\n",
    "encoder.save(\"encoder_model.h5\")\n",
    "decoder.save(\"decoder_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
