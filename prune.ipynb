{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP14.edf\n",
      "DP18.edf\n",
      "DP141.edf\n",
      "DP142.edf\n",
      "DP15.edf\n",
      "(369495, 64, 2)\n",
      "0.697108553566354\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "#Samples are represented in 16-bit 2's complement\n",
    "\n",
    "# Get the directory where the script is located\n",
    "script_dir = os.getcwd()\n",
    "file_counter = 0\n",
    "Files = []\n",
    "badFiles = []\n",
    "# Construct the full path to the file\n",
    "file_path = os.path.join(script_dir, 'EDF', 'PD patient Frontal')\n",
    "for filename in os.listdir(file_path):\n",
    "    # Check if the file ends with .edf\n",
    "    if filename.endswith('.edf'):\n",
    "        file_counter = file_counter+1\n",
    "        Files.append(filename)\n",
    "for k in np.arange(file_counter):\n",
    "    path = os.path.join(file_path, Files[k])\n",
    "    try:\n",
    "        f = pyedflib.EdfReader(path)\n",
    "    except OSError:\n",
    "        badFiles.append(Files[k])     \n",
    "Files = [item for item in Files if item not in badFiles]\n",
    "Files.reverse()\n",
    "n = f.signals_in_file\n",
    "n = n-9\n",
    "number_of_samples = f.getNSamples()[0]\n",
    "Nblocks = int((number_of_samples-250)/64)\n",
    "TotalBlocks=(5*Nblocks)*n\n",
    "fuller_data = np.ndarray(shape=(TotalBlocks, 64, 2))\n",
    "BlockCount=0\n",
    "multiplier = f.getPhysicalMaximum(0)/f.getDigitalMaximum(0)\n",
    "f.close()\n",
    "for index, name in enumerate(Files):\n",
    "    print(name)\n",
    "    path = os.path.join(file_path, name)\n",
    "    f = pyedflib.EdfReader(path)\n",
    "    number_of_samples = f.getNSamples()[0]\n",
    "    Nblocks = int((number_of_samples-250)/64)\n",
    "    sigbufs = np.zeros(number_of_samples)\n",
    "    full_data64 = np.ndarray(shape=(Nblocks*n, 64, 2))\n",
    "    signalList = []  \n",
    "    BlockCount = BlockCount+Nblocks*n\n",
    "    ran = np.ndarray(shape=(21, number_of_samples-250))\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[:] = f.readSignal(i, digital=True)\n",
    "        sigbufs_new = sigbufs[250:]\n",
    "        #ran[i] = sigbufs_new\n",
    "        signalList.append(sigbufs_new) \n",
    "        labels = np.zeros(number_of_samples-250)\n",
    "        if name == \"DP14.edf\":\n",
    "            sezStart = 79650\n",
    "            sezEnd = 82250\n",
    "            labels[sezStart:sezEnd] = 1\n",
    "        elif name == \"DP141.edf\":\n",
    "            sezStart = 103500\n",
    "            sezEnd = 106500\n",
    "            labels[sezStart:sezEnd] = 1\n",
    "        elif name == \"DP142.edf\":\n",
    "            sezStart = 223250\n",
    "            sezEnd = 224750\n",
    "            labels[sezStart:sezEnd] = 1\n",
    "        elif name == \"DP18.edf\":\n",
    "            sezStart = 93250\n",
    "            sezEnd = 94000\n",
    "            labels[sezStart:sezEnd] = 1\n",
    "        for j in np.arange(Nblocks):\n",
    "                full_data64[i*Nblocks+j,:,0] = signalList[i][j*64:(j+1)*64]\n",
    "                full_data64[i*Nblocks+j,:,1] = labels[j*64:(j+1)*64]\n",
    "    fuller_data[BlockCount-Nblocks*n:BlockCount] = full_data64\n",
    "    f.close()\n",
    "seizures = np.sum(fuller_data[:,:,1] == 1) \n",
    "normal = np.sum(fuller_data[:,:,1] == 0)\n",
    "percentage_seizure = seizures/(seizures+normal)*100\n",
    "print(fuller_data.shape)\n",
    "print(percentage_seizure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 22:10:16.936236: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 22:10:16.936288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 22:10:16.937631: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 22:10:16.943216: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 22:10:18.036510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "\n",
    "NSTEPS = int(369495 * 0.8) // 128 \n",
    "\n",
    "def pruneFunction(layer):\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': sparsity.PolynomialDecay(\n",
    "            initial_sparsity=0.0, final_sparsity=0.3, begin_step=NSTEPS * 2, end_step=NSTEPS * 10, frequency=NSTEPS\n",
    "        )\n",
    "    }\n",
    "    if isinstance(layer, tf.keras.layers.Conv1D):\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "    if isinstance(layer, tf.keras.layers.Dense) and layer.name != 'output_dense':\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prd_loss_dig2phy(y_true, y_pred):\n",
    "    y_true = (y_true)*multiplier\n",
    "    y_pred = (y_pred)*multiplier\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_mse_loss(y_true, y_pred):\n",
    "    # y_true, y_pred shape: (batch_size, num_channels, signal_length)\n",
    "    # label shape: (batch_size, )\n",
    "    weight = 150\n",
    "    # Extract the labels (0 or 1) from the last dimension of y_true\n",
    "    labels = y_true[:, :, 1]\n",
    "    # Remove the labels from y_true for loss calculation\n",
    "    y_true_processed = y_true[:, :, 0]\n",
    "    y_true_processed=y_true_processed[..., tf.newaxis]\n",
    "    loss = K.mean(K.square(y_pred - y_true_processed))\n",
    "    weighted_loss = loss * ((labels * (weight - 1)) + 1)\n",
    "    return K.mean(weighted_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prd_loss_dig2phy_new(y_true, y_pred):\n",
    "    y_true_processed = y_true[:, :, 0]\n",
    "    y_true_processed = y_true_processed[..., tf.newaxis]\n",
    "    y_true_processed = (y_true_processed)*multiplier\n",
    "    y_pred = (y_pred)*multiplier\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true_processed - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true_processed))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_time_series (InputLa  [(None, 64, 1)]           0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " q_conv1d (QConv1D)          (None, 64, 8)             32        \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 64, 8)             0         \n",
      "                                                                 \n",
      " q_conv1d_1 (QConv1D)        (None, 64, 8)             328       \n",
      "                                                                 \n",
      " q_activation_1 (QActivatio  (None, 64, 8)             0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_conv1d_2 (QConv1D)        (None, 32, 4)             164       \n",
      "                                                                 \n",
      " q_activation_2 (QActivatio  (None, 32, 4)             0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_conv1d_3 (QConv1D)        (None, 16, 4)             84        \n",
      "                                                                 \n",
      " q_activation_3 (QActivatio  (None, 16, 4)             0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 16)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1648 (6.44 KB)\n",
      "Trainable params: 1648 (6.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from qkeras import quantizers\n",
    "from qkeras import QConv1D, QDense, QActivation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qkeras import quantizers\n",
    "from qkeras import QConv1D, QDense, QActivation\n",
    "from qkeras.utils import load_qmodel\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the encoder with quantization\n",
    "input_ts = keras.layers.Input(shape=(64, 1), name=\"input_time_series\")  # 64, 1\n",
    "\n",
    "# First Conv1D layer with quantized activations\n",
    "x = QConv1D(8, 3, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same')(input_ts)  # 64, 16\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)  # Quantized activations to 16 bits\n",
    "# Second Conv1D layer with quantized activations\n",
    "x = QConv1D(8, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same')(x)  # 64, 16\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Third Conv1D layer with quantized activations\n",
    "x = QConv1D(4, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same', \n",
    "            strides=2)(x)  # 32, 8\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Fourth Conv1D layer with quantized activations\n",
    "x = QConv1D(4, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same', \n",
    "            strides=2)(x)  # 16, 4\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Flatten layer\n",
    "x = keras.layers.Flatten()(x)  # Flatten for Dense layer\n",
    "\n",
    "# Dense layer with quantized activations\n",
    "x = QDense(16, kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "                 bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1))(x)  # 16\n",
    "encoded = keras.layers.Activation(activation='linear')(x)\n",
    "\n",
    "# Define the model\n",
    "encoder = keras.models.Model(input_ts, encoded, name=\"encoder\")\n",
    "\n",
    "# Print the model summary\n",
    "encoder.summary()\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input = keras.layers.Input(shape=(16,), name=\"encoded_input\") # 16\n",
    "x = keras.layers.Dense(16 * 4, activation='linear')(encoded_input) # 16 * 4\n",
    "x = keras.layers.Reshape((16, 4))(x) # Reshape back to (16, 4)\n",
    "x = keras.layers.Conv1DTranspose(8, 5, activation='linear', strides=2, padding='same')(x) # 16, 8\n",
    "x = keras.layers.Conv1DTranspose(16, 5, activation='linear', strides=2, padding='same')(x) # 32, 16\n",
    "x = keras.layers.Conv1DTranspose(8, 7, activation='linear', padding='same')(x) # 32, 16\n",
    "decoded = keras.layers.Conv1DTranspose(1, 3, activation='linear', padding='same')(x) # 64, 1\n",
    "\n",
    "decoder = keras.models.Model(encoded_input, decoded, name=\"decoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: QConv1D.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prunedQenocder \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpruneFunction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/models/cloning.py:540\u001b[0m, in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, functional\u001b[38;5;241m.\u001b[39mFunctional):\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;66;03m# If the get_config() method is the same as a regular Functional\u001b[39;00m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# model, we're safe to use _clone_functional_model (which relies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;66;03m# or input_tensors are passed, we attempt it anyway\u001b[39;00m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;66;03m# in order to preserve backwards compatibility.\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generic_utils\u001b[38;5;241m.\u001b[39mis_default(model\u001b[38;5;241m.\u001b[39mget_config) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    538\u001b[0m         clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors\n\u001b[1;32m    539\u001b[0m     ):\n\u001b[0;32m--> 540\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_functional_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_function\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# Case of a custom model class\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors:\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/models/cloning.py:222\u001b[0m, in \u001b[0;36m_clone_functional_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    218\u001b[0m         model_configs, created_layers \u001b[38;5;241m=\u001b[39m _clone_layers_and_model_config(\n\u001b[1;32m    219\u001b[0m             model, new_input_layers, layer_fn\n\u001b[1;32m    220\u001b[0m         )\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     model_configs, created_layers \u001b[38;5;241m=\u001b[39m \u001b[43m_clone_layers_and_model_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_input_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_fn\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Reconstruct model from the config, using the cloned layers.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m (\n\u001b[1;32m    227\u001b[0m     input_tensors,\n\u001b[1;32m    228\u001b[0m     output_tensors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m     model_configs, created_layers\u001b[38;5;241m=\u001b[39mcreated_layers\n\u001b[1;32m    232\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/models/cloning.py:298\u001b[0m, in \u001b[0;36m_clone_layers_and_model_config\u001b[0;34m(model, input_layers, layer_fn)\u001b[0m\n\u001b[1;32m    295\u001b[0m         created_layers[layer\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m layer_fn(layer)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[0;32m--> 298\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_network_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserialize_layer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_copy_layer\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config, created_layers\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/engine/functional.py:1593\u001b[0m, in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn, config)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Functional) \u001b[38;5;129;01mand\u001b[39;00m set_layers_legacy:\n\u001b[1;32m   1592\u001b[0m     layer\u001b[38;5;241m.\u001b[39muse_legacy_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1593\u001b[0m layer_config \u001b[38;5;241m=\u001b[39m \u001b[43mserialize_layer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m layer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   1595\u001b[0m layer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minbound_nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered_inbound_nodes\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/models/cloning.py:295\u001b[0m, in \u001b[0;36m_clone_layers_and_model_config.<locals>._copy_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    293\u001b[0m     created_layers[layer\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m InputLayer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlayer\u001b[38;5;241m.\u001b[39mget_config())\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     created_layers[layer\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {}\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mpruneFunction\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     12\u001b[0m pruning_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpruning_schedule\u001b[39m\u001b[38;5;124m'\u001b[39m: sparsity\u001b[38;5;241m.\u001b[39mPolynomialDecay(\n\u001b[1;32m     14\u001b[0m         initial_sparsity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, final_sparsity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, begin_step\u001b[38;5;241m=\u001b[39mNSTEPS \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, end_step\u001b[38;5;241m=\u001b[39mNSTEPS \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m, frequency\u001b[38;5;241m=\u001b[39mNSTEPS\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1D):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtfmot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparsity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprune_low_magnitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpruning_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense) \u001b[38;5;129;01mand\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dense\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tfmot\u001b[38;5;241m.\u001b[39msparsity\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mprune_low_magnitude(layer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpruning_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:74\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_FAILURE_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 74\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/keras/metrics.py:69\u001b[0m, in \u001b[0;36mMonitorBoolGauge.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbool_gauge\u001b[38;5;241m.\u001b[39mget_cell(MonitorBoolGauge\u001b[38;5;241m.\u001b[39m_SUCCESS_LABEL)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/prune.py:216\u001b[0m, in \u001b[0;36mprune_low_magnitude\u001b[0;34m(to_prune, pruning_schedule, block_size, block_pooling_type, pruning_policy, sparsity_m_by_n, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m pruning_wrapper\u001b[38;5;241m.\u001b[39mPruneLowMagnitude(to_prune, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 216\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`prune_low_magnitude` can only prune an object of the following \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtypes: keras.models.Sequential, keras functional model, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    219\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.layers.Layer, list of keras.layers.Layer. You passed \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    220\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man object of type: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mto_prune\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    221\u001b[0m   )\n",
      "\u001b[0;31mValueError\u001b[0m: `prune_low_magnitude` can only prune an object of the following types: keras.models.Sequential, keras functional model, keras.layers.Layer, list of keras.layers.Layer. You passed an object of type: QConv1D."
     ]
    }
   ],
   "source": [
    "prunedQenocder = tf.keras.models.clone_model(encoder, clone_function=pruneFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder\n",
    "autoencoder_input = keras.layers.Input(shape=(64, 1), name=\"autoencoder_input\")\n",
    "encoded_ts = encoder(autoencoder_input)\n",
    "decoded_ts = decoder(encoded_ts)\n",
    "autoencoder = keras.models.Model(autoencoder_input, decoded_ts, name=\"autoencoder\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.00001), loss=weighted_mse_loss, metrics=[prd_loss_dig2phy_new])\n",
    "weight_model = load_qmodel('quantised.h5', custom_objects={'prd_loss_dig2phy_new': prd_loss_dig2phy_new, 'weighted_mse_loss': weighted_mse_loss})\n",
    "# Summary of the autoencoder\n",
    "autoencoder.summary()\n",
    "autoencoder.set_weights(weight_model.get_weights())\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='inter1_quantised.h5',  # Path to save the model\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='min',                # Mode: minimize the monitored metric\n",
    "    verbose=1                  # Print a message when saving the model\n",
    ")\n",
    "#features_train = fuller_data[:, :, 0]\n",
    "# features_val = val_data[:, :, 0]\n",
    "\n",
    "new_train, new_val = train_test_split(fuller_data, test_size=0.2, random_state=69)\n",
    "features_val = new_val[:, :, 0]\n",
    "features_val = features_val[..., tf.newaxis]\n",
    "features_train = new_train[:, :, 0]\n",
    "features_train = features_train[..., tf.newaxis]\n",
    "pred = autoencoder.predict(features_val)\n",
    "print(prd_loss_dig2phy(features_val, pred).numpy())\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(features_train, new_train, epochs=30, batch_size=128, shuffle=True, callbacks=[checkpoint_callback], validation_data=(features_val, new_val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qkeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
