{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP14.edf\n",
      "DP18.edf\n",
      "DP141.edf\n",
      "DP142.edf\n",
      "DP15.edf\n",
      "(369495, 64, 2)\n",
      "0.697108553566354\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "#Samples are represented in 16-bit 2's complement\n",
    "\n",
    "# Get the directory where the script is located\n",
    "script_dir = os.getcwd()\n",
    "file_counter = 0\n",
    "Files = []\n",
    "badFiles = []\n",
    "# Construct the full path to the file\n",
    "file_path = os.path.join(script_dir, 'EDF', 'PD patient Frontal')\n",
    "for filename in os.listdir(file_path):\n",
    "    # Check if the file ends with .edf\n",
    "    if filename.endswith('.edf'):\n",
    "        file_counter = file_counter+1\n",
    "        Files.append(filename)\n",
    "for k in np.arange(file_counter):\n",
    "    path = os.path.join(file_path, Files[k])\n",
    "    try:\n",
    "        f = pyedflib.EdfReader(path)\n",
    "    except OSError:\n",
    "        badFiles.append(Files[k])     \n",
    "Files = [item for item in Files if item not in badFiles]\n",
    "Files.reverse()\n",
    "n = f.signals_in_file\n",
    "n = n-9\n",
    "number_of_samples = f.getNSamples()[0]\n",
    "Nblocks = int((number_of_samples-250)/64)\n",
    "TotalBlocks=(5*Nblocks)*n\n",
    "fuller_data = np.ndarray(shape=(TotalBlocks, 64, 2))\n",
    "BlockCount=0\n",
    "multiplier = f.getPhysicalMaximum(0)/f.getDigitalMaximum(0)\n",
    "f.close()\n",
    "for index, name in enumerate(Files):\n",
    "    print(name)\n",
    "    path = os.path.join(file_path, name)\n",
    "    f = pyedflib.EdfReader(path)\n",
    "    number_of_samples = f.getNSamples()[0]\n",
    "    Nblocks = int((number_of_samples-250)/64)\n",
    "    sigbufs = np.zeros(number_of_samples)\n",
    "    full_data64 = np.ndarray(shape=(Nblocks*n, 64, 2))\n",
    "    signalList = []  \n",
    "    BlockCount = BlockCount+Nblocks*n\n",
    "    ran = np.ndarray(shape=(21, number_of_samples-250))\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[:] = f.readSignal(i, digital=True)\n",
    "        sigbufs_new = sigbufs[250:]\n",
    "        #ran[i] = sigbufs_new\n",
    "        signalList.append(sigbufs_new) \n",
    "        labels = np.zeros(number_of_samples-250)\n",
    "        if name == \"DP14.edf\":\n",
    "            sezStart = 79650\n",
    "            sezEnd = 82250\n",
    "            labels[sezStart:sezEnd] = 1\n",
    "        elif name == \"DP141.edf\":\n",
    "            sezStart = 103500\n",
    "            sezEnd = 106500\n",
    "            labels[sezStart:sezEnd] = 1\n",
    "        elif name == \"DP142.edf\":\n",
    "            sezStart = 223250\n",
    "            sezEnd = 224750\n",
    "            labels[sezStart:sezEnd] = 1\n",
    "        elif name == \"DP18.edf\":\n",
    "            sezStart = 93250\n",
    "            sezEnd = 94000\n",
    "            labels[sezStart:sezEnd] = 1\n",
    "        for j in np.arange(Nblocks):\n",
    "                full_data64[i*Nblocks+j,:,0] = signalList[i][j*64:(j+1)*64]\n",
    "                full_data64[i*Nblocks+j,:,1] = labels[j*64:(j+1)*64]\n",
    "    fuller_data[BlockCount-Nblocks*n:BlockCount] = full_data64\n",
    "    f.close()\n",
    "seizures = np.sum(fuller_data[:,:,1] == 1) \n",
    "normal = np.sum(fuller_data[:,:,1] == 0)\n",
    "percentage_seizure = seizures/(seizures+normal)*100\n",
    "print(fuller_data.shape)\n",
    "print(percentage_seizure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def prd_loss_dig2phy_new(y_true, y_pred):\n",
    "    y_true_processed = y_true[:, :, 0]\n",
    "    y_true_processed = y_true_processed[..., tf.newaxis]\n",
    "    y_true_processed = (y_true_processed)*multiplier\n",
    "    y_pred = (y_pred)*multiplier\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true_processed - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true_processed))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def weighted_mse_loss(y_true, y_pred):\n",
    "    # y_true, y_pred shape: (batch_size, num_channels, signal_length)\n",
    "    # label shape: (batch_size, )\n",
    "    weight = 150\n",
    "    # Extract the labels (0 or 1) from the last dimension of y_true\n",
    "    labels = y_true[:, :, 1]\n",
    "    # Remove the labels from y_true for loss calculation\n",
    "    y_true_processed = y_true[:, :, 0]\n",
    "    y_true_processed=y_true_processed[..., tf.newaxis]\n",
    "    loss = K.mean(K.square(y_pred - y_true_processed))\n",
    "    weighted_loss = loss * ((labels * (weight - 1)) + 1)\n",
    "    return K.mean(weighted_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def prd_loss_dig2phy(y_true, y_pred):\n",
    "    y_true = (y_true)*multiplier\n",
    "    y_pred = (y_pred)*multiplier\n",
    "    rms_deviation = (tf.reduce_sum(tf.square(y_true - y_pred)))\n",
    "    percentage_rmsd = tf.sqrt(rms_deviation/(tf.reduce_sum(tf.square(y_true))+tf.keras.backend.epsilon()))* 100\n",
    "    return percentage_rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.utils import load_qmodel\n",
    "from keras import layers, Sequential\n",
    "Qencoder = load_qmodel('Qencoder.h5')\n",
    "Qencoder.summary()\n",
    "layer1 = Qencoder.get_layer('q_conv1d_1')\n",
    "weights = layer1.get_weights()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 15:07:15.694828: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:15.887540: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:15.887766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:15.890228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:15.890437: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:15.890606: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:18.192957: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:18.193678: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:18.193696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-08-05 15:07:18.194171: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-05 15:07:18.194213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2073 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-08-05 15:07:18.537944: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_time_series (InputLa  [(None, 64, 1)]           0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " q_conv1d (QConv1D)          (None, 64, 8)             32        \n",
      "                                                                 \n",
      " q_conv1d_1 (QConv1D)        (None, 64, 8)             328       \n",
      "                                                                 \n",
      " q_conv1d_2 (QConv1D)        (None, 32, 4)             164       \n",
      "                                                                 \n",
      " q_conv1d_3 (QConv1D)        (None, 16, 4)             84        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 16)                1040      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1648 (6.44 KB)\n",
      "Trainable params: 1648 (6.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " autoencoder_input (InputLa  [(None, 64, 1)]           0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                1648      \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 64, 1)             2841      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4489 (17.54 KB)\n",
      "Trainable params: 4489 (17.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 15:07:25.777937: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-08-05 15:07:27.689071: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-08-05 15:07:29.622295: I external/local_xla/xla/service/service.cc:168] XLA service 0x4625d840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-05 15:07:29.622341: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti, Compute Capability 7.5\n",
      "2024-08-05 15:07:29.643896: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722866849.747892  361351 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2310/2310 [==============================] - ETA: 0s - loss: 49440.7070 - prd_loss_dig2phy_new: 52.4926\n",
      "Epoch 1: val_loss improved from inf to 36747.25391, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 48s 16ms/step - loss: 49440.7070 - prd_loss_dig2phy_new: 52.4926 - val_loss: 36747.2539 - val_prd_loss_dig2phy_new: 37.3019\n",
      "Epoch 2/30\n",
      "  11/2310 [..............................] - ETA: 25s - loss: 31692.8516 - prd_loss_dig2phy_new: 32.6840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkb/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/home/berkb/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2310/2310 [==============================] - ETA: 0s - loss: 28029.5762 - prd_loss_dig2phy_new: 35.9826\n",
      "Epoch 2: val_loss improved from 36747.25391 to 26263.85352, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 36s 16ms/step - loss: 28029.5762 - prd_loss_dig2phy_new: 35.9826 - val_loss: 26263.8535 - val_prd_loss_dig2phy_new: 29.6533\n",
      "Epoch 3/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 20964.1914 - prd_loss_dig2phy_new: 33.5341\n",
      "Epoch 3: val_loss did not improve from 26263.85352\n",
      "2310/2310 [==============================] - 36s 16ms/step - loss: 20963.5215 - prd_loss_dig2phy_new: 33.5464 - val_loss: 67015.1719 - val_prd_loss_dig2phy_new: 61.9282\n",
      "Epoch 4/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 17776.8711 - prd_loss_dig2phy_new: 30.4397\n",
      "Epoch 4: val_loss improved from 26263.85352 to 21695.84570, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 46s 20ms/step - loss: 17774.2852 - prd_loss_dig2phy_new: 30.4336 - val_loss: 21695.8457 - val_prd_loss_dig2phy_new: 28.0724\n",
      "Epoch 5/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 17713.6641 - prd_loss_dig2phy_new: 28.1806\n",
      "Epoch 5: val_loss improved from 21695.84570 to 19971.55273, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 42s 18ms/step - loss: 17705.3379 - prd_loss_dig2phy_new: 28.1844 - val_loss: 19971.5527 - val_prd_loss_dig2phy_new: 25.3027\n",
      "Epoch 6/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 16340.2168 - prd_loss_dig2phy_new: 29.0656\n",
      "Epoch 6: val_loss did not improve from 19971.55273\n",
      "2310/2310 [==============================] - 38s 16ms/step - loss: 16324.1514 - prd_loss_dig2phy_new: 29.0515 - val_loss: 20977.9355 - val_prd_loss_dig2phy_new: 26.5043\n",
      "Epoch 7/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 14183.0537 - prd_loss_dig2phy_new: 26.9287\n",
      "Epoch 7: val_loss did not improve from 19971.55273\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 14180.9746 - prd_loss_dig2phy_new: 26.9264 - val_loss: 21400.4609 - val_prd_loss_dig2phy_new: 27.5370\n",
      "Epoch 8/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 18133.4902 - prd_loss_dig2phy_new: 30.0661\n",
      "Epoch 8: val_loss improved from 19971.55273 to 17738.92383, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 18116.6426 - prd_loss_dig2phy_new: 30.0525 - val_loss: 17738.9238 - val_prd_loss_dig2phy_new: 24.1652\n",
      "Epoch 9/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 10773.7930 - prd_loss_dig2phy_new: 24.5867\n",
      "Epoch 9: val_loss improved from 17738.92383 to 16448.35742, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 38s 16ms/step - loss: 10772.1992 - prd_loss_dig2phy_new: 24.5847 - val_loss: 16448.3574 - val_prd_loss_dig2phy_new: 23.1238\n",
      "Epoch 10/30\n",
      "2306/2310 [============================>.] - ETA: 0s - loss: 12587.4531 - prd_loss_dig2phy_new: 25.9809\n",
      "Epoch 10: val_loss did not improve from 16448.35742\n",
      "2310/2310 [==============================] - 36s 16ms/step - loss: 12570.1914 - prd_loss_dig2phy_new: 25.9686 - val_loss: 17064.2461 - val_prd_loss_dig2phy_new: 24.1739\n",
      "Epoch 11/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 10981.5244 - prd_loss_dig2phy_new: 24.3463\n",
      "Epoch 11: val_loss did not improve from 16448.35742\n",
      "2310/2310 [==============================] - 35s 15ms/step - loss: 10981.5244 - prd_loss_dig2phy_new: 24.3463 - val_loss: 20696.1387 - val_prd_loss_dig2phy_new: 28.7247\n",
      "Epoch 12/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 13318.5781 - prd_loss_dig2phy_new: 25.9217\n",
      "Epoch 12: val_loss did not improve from 16448.35742\n",
      "2310/2310 [==============================] - 38s 17ms/step - loss: 13318.5781 - prd_loss_dig2phy_new: 25.9217 - val_loss: 16674.4297 - val_prd_loss_dig2phy_new: 23.3462\n",
      "Epoch 13/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 12394.5488 - prd_loss_dig2phy_new: 25.7326\n",
      "Epoch 13: val_loss improved from 16448.35742 to 15138.00586, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 36s 16ms/step - loss: 12388.2354 - prd_loss_dig2phy_new: 25.7212 - val_loss: 15138.0059 - val_prd_loss_dig2phy_new: 21.8784\n",
      "Epoch 14/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 10660.1094 - prd_loss_dig2phy_new: 23.7427\n",
      "Epoch 14: val_loss did not improve from 15138.00586\n",
      "2310/2310 [==============================] - 39s 17ms/step - loss: 10654.7314 - prd_loss_dig2phy_new: 23.7438 - val_loss: 21013.0059 - val_prd_loss_dig2phy_new: 27.9769\n",
      "Epoch 15/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 9336.5801 - prd_loss_dig2phy_new: 23.2441\n",
      "Epoch 15: val_loss did not improve from 15138.00586\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 9328.4521 - prd_loss_dig2phy_new: 23.2467 - val_loss: 17604.2539 - val_prd_loss_dig2phy_new: 25.8815\n",
      "Epoch 16/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 10213.8086 - prd_loss_dig2phy_new: 24.5718\n",
      "Epoch 16: val_loss did not improve from 15138.00586\n",
      "2310/2310 [==============================] - 34s 15ms/step - loss: 10260.4141 - prd_loss_dig2phy_new: 24.5916 - val_loss: 18469.0469 - val_prd_loss_dig2phy_new: 25.9900\n",
      "Epoch 17/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 13087.0703 - prd_loss_dig2phy_new: 25.8567\n",
      "Epoch 17: val_loss did not improve from 15138.00586\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 13278.8848 - prd_loss_dig2phy_new: 25.8502 - val_loss: 15418.4932 - val_prd_loss_dig2phy_new: 22.3795\n",
      "Epoch 18/30\n",
      "2306/2310 [============================>.] - ETA: 0s - loss: 13806.7812 - prd_loss_dig2phy_new: 26.4774\n",
      "Epoch 18: val_loss did not improve from 15138.00586\n",
      "2310/2310 [==============================] - 36s 15ms/step - loss: 13788.6543 - prd_loss_dig2phy_new: 26.4735 - val_loss: 16517.4609 - val_prd_loss_dig2phy_new: 24.6729\n",
      "Epoch 19/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 9775.3418 - prd_loss_dig2phy_new: 22.5543\n",
      "Epoch 19: val_loss did not improve from 15138.00586\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 9773.9082 - prd_loss_dig2phy_new: 22.5515 - val_loss: 15891.7842 - val_prd_loss_dig2phy_new: 23.0261\n",
      "Epoch 20/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 10803.8125 - prd_loss_dig2phy_new: 24.6039\n",
      "Epoch 20: val_loss did not improve from 15138.00586\n",
      "2310/2310 [==============================] - 36s 16ms/step - loss: 10802.2822 - prd_loss_dig2phy_new: 24.6012 - val_loss: 20976.6406 - val_prd_loss_dig2phy_new: 28.6446\n",
      "Epoch 21/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 10122.8877 - prd_loss_dig2phy_new: 23.1786\n",
      "Epoch 21: val_loss improved from 15138.00586 to 14807.84961, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 10113.1152 - prd_loss_dig2phy_new: 23.1683 - val_loss: 14807.8496 - val_prd_loss_dig2phy_new: 21.6590\n",
      "Epoch 22/30\n",
      "2306/2310 [============================>.] - ETA: 0s - loss: 9794.1670 - prd_loss_dig2phy_new: 22.6691\n",
      "Epoch 22: val_loss did not improve from 14807.84961\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 9780.6572 - prd_loss_dig2phy_new: 22.6668 - val_loss: 17838.3047 - val_prd_loss_dig2phy_new: 25.3588\n",
      "Epoch 23/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 11808.0498 - prd_loss_dig2phy_new: 24.8805\n",
      "Epoch 23: val_loss did not improve from 14807.84961\n",
      "2310/2310 [==============================] - 36s 15ms/step - loss: 11808.0498 - prd_loss_dig2phy_new: 24.8805 - val_loss: 43030.5898 - val_prd_loss_dig2phy_new: 41.9062\n",
      "Epoch 24/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 10356.3799 - prd_loss_dig2phy_new: 23.2200\n",
      "Epoch 24: val_loss did not improve from 14807.84961\n",
      "2310/2310 [==============================] - 34s 15ms/step - loss: 10347.0508 - prd_loss_dig2phy_new: 23.2149 - val_loss: 14873.8916 - val_prd_loss_dig2phy_new: 21.9920\n",
      "Epoch 25/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 9765.9717 - prd_loss_dig2phy_new: 23.0801\n",
      "Epoch 25: val_loss did not improve from 14807.84961\n",
      "2310/2310 [==============================] - 36s 15ms/step - loss: 9765.9717 - prd_loss_dig2phy_new: 23.0801 - val_loss: 21866.1855 - val_prd_loss_dig2phy_new: 28.1298\n",
      "Epoch 26/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 12457.6719 - prd_loss_dig2phy_new: 24.3719\n",
      "Epoch 26: val_loss improved from 14807.84961 to 14802.69922, saving model to quantised.h5\n",
      "2310/2310 [==============================] - 38s 16ms/step - loss: 12457.6719 - prd_loss_dig2phy_new: 24.3719 - val_loss: 14802.6992 - val_prd_loss_dig2phy_new: 21.6204\n",
      "Epoch 27/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 11028.0039 - prd_loss_dig2phy_new: 24.2808\n",
      "Epoch 27: val_loss did not improve from 14802.69922\n",
      "2310/2310 [==============================] - 36s 16ms/step - loss: 11050.5273 - prd_loss_dig2phy_new: 24.2804 - val_loss: 16016.1738 - val_prd_loss_dig2phy_new: 22.8715\n",
      "Epoch 28/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 8848.9775 - prd_loss_dig2phy_new: 21.8049\n",
      "Epoch 28: val_loss did not improve from 14802.69922\n",
      "2310/2310 [==============================] - 35s 15ms/step - loss: 8848.9775 - prd_loss_dig2phy_new: 21.8049 - val_loss: 26440.7852 - val_prd_loss_dig2phy_new: 36.1043\n",
      "Epoch 29/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 11450.3721 - prd_loss_dig2phy_new: 24.4643\n",
      "Epoch 29: val_loss did not improve from 14802.69922\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 11448.6885 - prd_loss_dig2phy_new: 24.4614 - val_loss: 15040.6953 - val_prd_loss_dig2phy_new: 21.7880\n",
      "Epoch 30/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 10007.2217 - prd_loss_dig2phy_new: 22.7581\n",
      "Epoch 30: val_loss did not improve from 14802.69922\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 9998.2070 - prd_loss_dig2phy_new: 22.7521 - val_loss: 15061.1426 - val_prd_loss_dig2phy_new: 21.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f19504ec1f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from qkeras import quantizers\n",
    "from qkeras import QConv1D, QDense, QActivation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the encoder with quantization\n",
    "input_ts = keras.layers.Input(shape=(64, 1), name=\"input_time_series\") # 64, 1\n",
    "\n",
    "# First Conv1D layer\n",
    "x = QConv1D(8, 3, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(15, 0, 1, alpha=1),\n",
    "            activation='linear', \n",
    "            padding='same', )(input_ts) # 64, 16\n",
    "\n",
    "# Second Conv1D layer\n",
    "x = QConv1D(8, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1),\n",
    "            activation='linear', \n",
    "            padding='same')(x) # 64, 16\n",
    "\n",
    "# Third Conv1D layer with strides\n",
    "x = QConv1D(4, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1),\n",
    "            activation='linear', \n",
    "            padding='same', \n",
    "            strides=2)(x) # 32, 8\n",
    "\n",
    "# Fourth Conv1D layer with strides\n",
    "x = QConv1D(4, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1),\n",
    "            activation='linear', \n",
    "            padding='same', \n",
    "            strides=2)(x) # 16, 4\n",
    "\n",
    "# Flatten layer\n",
    "x = keras.layers.Flatten()(x) # Flatten for Dense layer\n",
    "\n",
    "# Dense layer\n",
    "encoded = QDense(16, \n",
    "                 kernel_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1), \n",
    "                 bias_quantizer=quantizers.quantized_bits(12, 0, 1, alpha=1),\n",
    "                 activation='linear')(x) # 16\n",
    "\n",
    "# Define the model\n",
    "encoder = keras.models.Model(input_ts, encoded, name=\"encoder\")\n",
    "\n",
    "# Print the model summary\n",
    "encoder.summary()\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input = keras.layers.Input(shape=(16,), name=\"encoded_input\") # 16\n",
    "x = keras.layers.Dense(16 * 4, activation='linear')(encoded_input) # 16 * 4\n",
    "x = keras.layers.Reshape((16, 4))(x) # Reshape back to (16, 4)\n",
    "x = keras.layers.Conv1DTranspose(8, 5, activation='linear', strides=2, padding='same')(x) # 16, 8\n",
    "x = keras.layers.Conv1DTranspose(16, 5, activation='linear', strides=2, padding='same')(x) # 32, 16\n",
    "x = keras.layers.Conv1DTranspose(8, 7, activation='linear', padding='same')(x) # 32, 16\n",
    "decoded = keras.layers.Conv1DTranspose(1, 3, activation='linear', padding='same')(x) # 64, 1\n",
    "\n",
    "decoder = keras.models.Model(encoded_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Define the autoencoder\n",
    "autoencoder_input = keras.layers.Input(shape=(64, 1), name=\"autoencoder_input\")\n",
    "encoded_ts = encoder(autoencoder_input)\n",
    "decoded_ts = decoder(encoded_ts)\n",
    "\n",
    "autoencoder = keras.models.Model(autoencoder_input, decoded_ts, name=\"autoencoder\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss=weighted_mse_loss, metrics=[prd_loss_dig2phy_new])\n",
    "\n",
    "# Summary of the autoencoder\n",
    "autoencoder.summary()\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='quantised.h5',  # Path to save the model\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='min',                # Mode: minimize the monitored metric\n",
    "    verbose=1                  # Print a message when saving the model\n",
    ")\n",
    "#features_train = fuller_data[:, :, 0]\n",
    "# features_val = val_data[:, :, 0]\n",
    "\n",
    "new_train, new_val = train_test_split(fuller_data, test_size=0.2, random_state=69)\n",
    "features_val = new_val[:, :, 0]\n",
    "features_val = features_val[..., tf.newaxis]\n",
    "features_train = new_train[:, :, 0]\n",
    "features_train = features_train[..., tf.newaxis]\n",
    "#features_val = features_val[..., tf.newaxis]\n",
    "#print(features_train.shape)\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(features_train, new_train, epochs=30, shuffle=True, batch_size = 128, callbacks=[checkpoint_callback], validation_data=(features_val, new_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_time_series (InputLa  [(None, 64, 1)]           0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " q_conv1d_16 (QConv1D)       (None, 64, 8)             32        \n",
      "                                                                 \n",
      " q_activation_20 (QActivati  (None, 64, 8)             0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " q_conv1d_17 (QConv1D)       (None, 64, 8)             328       \n",
      "                                                                 \n",
      " q_activation_21 (QActivati  (None, 64, 8)             0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " q_conv1d_18 (QConv1D)       (None, 32, 4)             164       \n",
      "                                                                 \n",
      " q_activation_22 (QActivati  (None, 32, 4)             0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " q_conv1d_19 (QConv1D)       (None, 16, 4)             84        \n",
      "                                                                 \n",
      " q_activation_23 (QActivati  (None, 16, 4)             0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " q_dense_4 (QDense)          (None, 16)                1040      \n",
      "                                                                 \n",
      " q_activation_24 (QActivati  (None, 16)                0         \n",
      " on)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1648 (6.44 KB)\n",
      "Trainable params: 1648 (6.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " autoencoder_input (InputLa  [(None, 64, 1)]           0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                1648      \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 64, 1)             2841      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4489 (17.54 KB)\n",
      "Trainable params: 4489 (17.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 9307.9365 - prd_loss_dig2phy_new: 21.0873\n",
      "Epoch 1: val_loss improved from inf to 16925.25977, saving model to real_quantised.h5\n",
      "2310/2310 [==============================] - 44s 17ms/step - loss: 9307.9365 - prd_loss_dig2phy_new: 21.0873 - val_loss: 16925.2598 - val_prd_loss_dig2phy_new: 21.9124\n",
      "Epoch 2/30\n",
      "   9/2310 [..............................] - ETA: 32s - loss: 2028.0022 - prd_loss_dig2phy_new: 19.7551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkb/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/home/berkb/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2308/2310 [============================>.] - ETA: 0s - loss: 10307.5283 - prd_loss_dig2phy_new: 21.7544\n",
      "Epoch 2: val_loss did not improve from 16925.25977\n",
      "2310/2310 [==============================] - 44s 19ms/step - loss: 10301.9971 - prd_loss_dig2phy_new: 21.7520 - val_loss: 18517.0078 - val_prd_loss_dig2phy_new: 22.1772\n",
      "Epoch 3/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 13783.1143 - prd_loss_dig2phy_new: 24.9550\n",
      "Epoch 3: val_loss did not improve from 16925.25977\n",
      "2310/2310 [==============================] - 41s 18ms/step - loss: 13781.1221 - prd_loss_dig2phy_new: 24.9516 - val_loss: 24855.1035 - val_prd_loss_dig2phy_new: 26.0663\n",
      "Epoch 4/30\n",
      "2306/2310 [============================>.] - ETA: 0s - loss: 26885.7715 - prd_loss_dig2phy_new: 40.0140\n",
      "Epoch 4: val_loss did not improve from 16925.25977\n",
      "2310/2310 [==============================] - 38s 17ms/step - loss: 26851.0586 - prd_loss_dig2phy_new: 40.0287 - val_loss: 58607.4297 - val_prd_loss_dig2phy_new: 50.0580\n",
      "Epoch 5/30\n",
      "1143/2310 [=============>................] - ETA: 17s - loss: 71808.8828 - prd_loss_dig2phy_new: 63.6888"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 94\u001b[0m\n\u001b[1;32m     90\u001b[0m features_train \u001b[38;5;241m=\u001b[39m features_train[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, tf\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#pred = autoencoder.predict(features_val)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#print(prd_loss_dig2phy(features_val, pred).numpy())\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Train the autoencoder\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/qkeras/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from qkeras import quantizers\n",
    "from qkeras import QConv1D, QDense, QActivation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qkeras import quantizers\n",
    "from qkeras import QConv1D, QDense, QActivation\n",
    "from qkeras.utils import load_qmodel\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the encoder with quantization\n",
    "input_ts = keras.layers.Input(shape=(64, 1), name=\"input_time_series\")  # 64, 1\n",
    "\n",
    "# First Conv1D layer with quantized activations\n",
    "x = QConv1D(8, 3, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same')(input_ts)  # 64, 16\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)  # Quantized activations to 16 bits\n",
    "# Second Conv1D layer with quantized activations\n",
    "x = QConv1D(8, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same')(x)  # 64, 16\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Third Conv1D layer with quantized activations\n",
    "x = QConv1D(4, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same', \n",
    "            strides=2)(x)  # 32, 8\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Fourth Conv1D layer with quantized activations\n",
    "x = QConv1D(4, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same', \n",
    "            strides=2)(x)  # 16, 4\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Flatten layer\n",
    "x = keras.layers.Flatten()(x)  # Flatten for Dense layer\n",
    "\n",
    "# Dense layer with quantized activations\n",
    "x = QDense(16, kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "                 bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1))(x)  # 16\n",
    "encoded = QActivation(activation= quantizers.quantized_bits(16, 15, alpha=1))(x)\n",
    "\n",
    "# Define the model\n",
    "encoder = keras.models.Model(input_ts, encoded, name=\"encoder\")\n",
    "\n",
    "# Print the model summary\n",
    "encoder.summary()\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input = keras.layers.Input(shape=(16,), name=\"encoded_input\") # 16\n",
    "x = keras.layers.Dense(16 * 4, activation='linear')(encoded_input) # 16 * 4\n",
    "x = keras.layers.Reshape((16, 4))(x) # Reshape back to (16, 4)\n",
    "x = keras.layers.Conv1DTranspose(8, 5, activation='linear', strides=2, padding='same')(x) # 16, 8\n",
    "x = keras.layers.Conv1DTranspose(16, 5, activation='linear', strides=2, padding='same')(x) # 32, 16\n",
    "x = keras.layers.Conv1DTranspose(8, 7, activation='linear', padding='same')(x) # 32, 16\n",
    "decoded = keras.layers.Conv1DTranspose(1, 3, activation='linear', padding='same')(x) # 64, 1\n",
    "\n",
    "decoder = keras.models.Model(encoded_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Define the autoencoder\n",
    "autoencoder_input = keras.layers.Input(shape=(64, 1), name=\"autoencoder_input\")\n",
    "encoded_ts = encoder(autoencoder_input)\n",
    "decoded_ts = decoder(encoded_ts)\n",
    "\n",
    "autoencoder = keras.models.Model(autoencoder_input, decoded_ts, name=\"autoencoder\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer= Adam(learning_rate=0.0001), loss=weighted_mse_loss, metrics=[prd_loss_dig2phy_new])\n",
    "weight_model = load_qmodel('inter1_quantised.h5', custom_objects={'prd_loss_dig2phy_new': prd_loss_dig2phy_new, 'weighted_mse_loss': weighted_mse_loss})\n",
    "# Summary of the autoencoder\n",
    "autoencoder.summary()\n",
    "autoencoder.set_weights(weight_model.get_weights())\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='real_quantised.h5',  # Path to save the model\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='min',                # Mode: minimize the monitored metric\n",
    "    verbose=1                  # Print a message when saving the model\n",
    ")\n",
    "new_train, new_val = train_test_split(fuller_data, test_size=0.2, random_state=69)\n",
    "features_val = new_val[:, :, 0]\n",
    "features_val = features_val[..., tf.newaxis]\n",
    "features_train = new_train[:, :, 0]\n",
    "features_train = features_train[..., tf.newaxis]\n",
    "#pred = autoencoder.predict(features_val)\n",
    "#print(prd_loss_dig2phy(features_val, pred).numpy())\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(features_train, new_train, epochs=30, batch_size=128, shuffle=True, callbacks=[checkpoint_callback], validation_data=(features_val, new_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_time_series (InputLa  [(None, 64, 1)]           0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " q_conv1d_8 (QConv1D)        (None, 64, 8)             32        \n",
      "                                                                 \n",
      " q_activation_4 (QActivatio  (None, 64, 8)             0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_conv1d_9 (QConv1D)        (None, 64, 8)             328       \n",
      "                                                                 \n",
      " q_activation_5 (QActivatio  (None, 64, 8)             0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_conv1d_10 (QConv1D)       (None, 32, 4)             164       \n",
      "                                                                 \n",
      " q_activation_6 (QActivatio  (None, 32, 4)             0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " q_conv1d_11 (QConv1D)       (None, 16, 4)             84        \n",
      "                                                                 \n",
      " q_activation_7 (QActivatio  (None, 16, 4)             0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 16)                1040      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1648 (6.44 KB)\n",
      "Trainable params: 1648 (6.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " autoencoder_input (InputLa  [(None, 64, 1)]           0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                1648      \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 64, 1)             2841      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4489 (17.54 KB)\n",
      "Trainable params: 4489 (17.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "2310/2310 [==============================] - 13s 5ms/step\n",
      "29.010975004678063\n",
      "Epoch 1/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 7993.2510 - prd_loss_dig2phy_new: 20.5528\n",
      "Epoch 1: val_loss improved from inf to 14678.71191, saving model to inter1_quantised.h5\n",
      "2310/2310 [==============================] - 40s 16ms/step - loss: 7993.2510 - prd_loss_dig2phy_new: 20.5528 - val_loss: 14678.7119 - val_prd_loss_dig2phy_new: 21.3743\n",
      "Epoch 2/30\n",
      "   4/2310 [..............................] - ETA: 47s - loss: 3088.3838 - prd_loss_dig2phy_new: 22.3374"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/berkb/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "/home/berkb/miniconda3/envs/qkeras/lib/python3.9/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2308/2310 [============================>.] - ETA: 0s - loss: 7207.9482 - prd_loss_dig2phy_new: 20.4545\n",
      "Epoch 2: val_loss improved from 14678.71191 to 14632.60742, saving model to inter1_quantised.h5\n",
      "2310/2310 [==============================] - 39s 17ms/step - loss: 7222.4810 - prd_loss_dig2phy_new: 20.4522 - val_loss: 14632.6074 - val_prd_loss_dig2phy_new: 21.3138\n",
      "Epoch 3/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 8719.5635 - prd_loss_dig2phy_new: 20.3892\n",
      "Epoch 3: val_loss improved from 14632.60742 to 14615.87012, saving model to inter1_quantised.h5\n",
      "2310/2310 [==============================] - 45s 20ms/step - loss: 8718.4561 - prd_loss_dig2phy_new: 20.3864 - val_loss: 14615.8701 - val_prd_loss_dig2phy_new: 21.2842\n",
      "Epoch 4/30\n",
      "2306/2310 [============================>.] - ETA: 0s - loss: 7311.6304 - prd_loss_dig2phy_new: 20.3505\n",
      "Epoch 4: val_loss improved from 14615.87012 to 14607.24414, saving model to inter1_quantised.h5\n",
      "2310/2310 [==============================] - 41s 18ms/step - loss: 7302.4912 - prd_loss_dig2phy_new: 20.3462 - val_loss: 14607.2441 - val_prd_loss_dig2phy_new: 21.2685\n",
      "Epoch 5/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 7808.8481 - prd_loss_dig2phy_new: 20.3700\n",
      "Epoch 5: val_loss improved from 14607.24414 to 14600.75586, saving model to inter1_quantised.h5\n",
      "2310/2310 [==============================] - 38s 16ms/step - loss: 7807.7075 - prd_loss_dig2phy_new: 20.3685 - val_loss: 14600.7559 - val_prd_loss_dig2phy_new: 21.2615\n",
      "Epoch 6/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 7805.4019 - prd_loss_dig2phy_new: 20.3080\n",
      "Epoch 6: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 7805.4019 - prd_loss_dig2phy_new: 20.3080 - val_loss: 14612.0537 - val_prd_loss_dig2phy_new: 21.2682\n",
      "Epoch 7/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 7837.9487 - prd_loss_dig2phy_new: 20.4270\n",
      "Epoch 7: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 41s 18ms/step - loss: 7838.2910 - prd_loss_dig2phy_new: 20.4282 - val_loss: 14616.3203 - val_prd_loss_dig2phy_new: 21.2645\n",
      "Epoch 8/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 7339.4766 - prd_loss_dig2phy_new: 20.2364\n",
      "Epoch 8: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 39s 17ms/step - loss: 7335.9761 - prd_loss_dig2phy_new: 20.2414 - val_loss: 14615.1670 - val_prd_loss_dig2phy_new: 21.2557\n",
      "Epoch 9/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 7734.8267 - prd_loss_dig2phy_new: 20.3651\n",
      "Epoch 9: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 38s 17ms/step - loss: 7730.6401 - prd_loss_dig2phy_new: 20.3664 - val_loss: 14615.0039 - val_prd_loss_dig2phy_new: 21.2526\n",
      "Epoch 10/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 8085.7251 - prd_loss_dig2phy_new: 20.4458\n",
      "Epoch 10: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 38s 16ms/step - loss: 8081.8291 - prd_loss_dig2phy_new: 20.4473 - val_loss: 14618.3438 - val_prd_loss_dig2phy_new: 21.2565\n",
      "Epoch 11/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 7743.6333 - prd_loss_dig2phy_new: 20.4808\n",
      "Epoch 11: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 41s 18ms/step - loss: 7746.1714 - prd_loss_dig2phy_new: 20.4888 - val_loss: 14613.1973 - val_prd_loss_dig2phy_new: 21.2465\n",
      "Epoch 12/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 7949.5210 - prd_loss_dig2phy_new: 20.4340\n",
      "Epoch 12: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 40s 17ms/step - loss: 7948.5151 - prd_loss_dig2phy_new: 20.4311 - val_loss: 14617.3564 - val_prd_loss_dig2phy_new: 21.2476\n",
      "Epoch 13/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 7968.4380 - prd_loss_dig2phy_new: 20.2944\n",
      "Epoch 13: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 7961.9077 - prd_loss_dig2phy_new: 20.2924 - val_loss: 14619.5938 - val_prd_loss_dig2phy_new: 21.2448\n",
      "Epoch 14/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 8158.9600 - prd_loss_dig2phy_new: 20.3814\n",
      "Epoch 14: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 40s 18ms/step - loss: 8154.5747 - prd_loss_dig2phy_new: 20.3816 - val_loss: 14629.6973 - val_prd_loss_dig2phy_new: 21.2487\n",
      "Epoch 15/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 7525.5386 - prd_loss_dig2phy_new: 20.4031\n",
      "Epoch 15: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 40s 18ms/step - loss: 7525.5386 - prd_loss_dig2phy_new: 20.4031 - val_loss: 14628.8447 - val_prd_loss_dig2phy_new: 21.2402\n",
      "Epoch 16/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 8097.3555 - prd_loss_dig2phy_new: 20.4022\n",
      "Epoch 16: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 38s 16ms/step - loss: 8096.1777 - prd_loss_dig2phy_new: 20.4018 - val_loss: 14645.4385 - val_prd_loss_dig2phy_new: 21.2530\n",
      "Epoch 17/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 7392.8760 - prd_loss_dig2phy_new: 20.4352\n",
      "Epoch 17: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 37s 16ms/step - loss: 7388.6611 - prd_loss_dig2phy_new: 20.4281 - val_loss: 14648.7920 - val_prd_loss_dig2phy_new: 21.2567\n",
      "Epoch 18/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 7771.0029 - prd_loss_dig2phy_new: 20.3879\n",
      "Epoch 18: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 41s 18ms/step - loss: 7765.7354 - prd_loss_dig2phy_new: 20.3862 - val_loss: 14647.8945 - val_prd_loss_dig2phy_new: 21.2541\n",
      "Epoch 19/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 7592.1943 - prd_loss_dig2phy_new: 20.3232\n",
      "Epoch 19: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 40s 18ms/step - loss: 7588.1567 - prd_loss_dig2phy_new: 20.3198 - val_loss: 14657.5576 - val_prd_loss_dig2phy_new: 21.2589\n",
      "Epoch 20/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 7379.7974 - prd_loss_dig2phy_new: 20.3061\n",
      "Epoch 20: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 38s 17ms/step - loss: 7376.0278 - prd_loss_dig2phy_new: 20.3005 - val_loss: 14678.6553 - val_prd_loss_dig2phy_new: 21.2877\n",
      "Epoch 21/30\n",
      "2306/2310 [============================>.] - ETA: 0s - loss: 7411.4092 - prd_loss_dig2phy_new: 20.3078\n",
      "Epoch 21: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 40s 17ms/step - loss: 7401.8813 - prd_loss_dig2phy_new: 20.3116 - val_loss: 14657.8105 - val_prd_loss_dig2phy_new: 21.2560\n",
      "Epoch 22/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 7315.8599 - prd_loss_dig2phy_new: 20.4342\n",
      "Epoch 22: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 41s 18ms/step - loss: 7315.1934 - prd_loss_dig2phy_new: 20.4336 - val_loss: 14659.5088 - val_prd_loss_dig2phy_new: 21.2619\n",
      "Epoch 23/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 7968.6802 - prd_loss_dig2phy_new: 20.4363\n",
      "Epoch 23: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 39s 17ms/step - loss: 7967.5371 - prd_loss_dig2phy_new: 20.4327 - val_loss: 14654.5391 - val_prd_loss_dig2phy_new: 21.2565\n",
      "Epoch 24/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 7796.0830 - prd_loss_dig2phy_new: 20.1782\n",
      "Epoch 24: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 38s 16ms/step - loss: 7796.0830 - prd_loss_dig2phy_new: 20.1782 - val_loss: 14674.2988 - val_prd_loss_dig2phy_new: 21.2786\n",
      "Epoch 25/30\n",
      "2310/2310 [==============================] - ETA: 0s - loss: 7219.4419 - prd_loss_dig2phy_new: 20.4180\n",
      "Epoch 25: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 41s 18ms/step - loss: 7219.4419 - prd_loss_dig2phy_new: 20.4180 - val_loss: 14647.5781 - val_prd_loss_dig2phy_new: 21.2497\n",
      "Epoch 26/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 7805.8267 - prd_loss_dig2phy_new: 20.4044\n",
      "Epoch 26: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 39s 17ms/step - loss: 7804.8647 - prd_loss_dig2phy_new: 20.4003 - val_loss: 14639.1494 - val_prd_loss_dig2phy_new: 21.2460\n",
      "Epoch 27/30\n",
      "2309/2310 [============================>.] - ETA: 0s - loss: 7163.6753 - prd_loss_dig2phy_new: 20.4276\n",
      "Epoch 27: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 39s 17ms/step - loss: 7162.6445 - prd_loss_dig2phy_new: 20.4253 - val_loss: 14663.0469 - val_prd_loss_dig2phy_new: 21.2845\n",
      "Epoch 28/30\n",
      "2308/2310 [============================>.] - ETA: 0s - loss: 8289.3223 - prd_loss_dig2phy_new: 20.3624\n",
      "Epoch 28: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 40s 17ms/step - loss: 8288.3252 - prd_loss_dig2phy_new: 20.3621 - val_loss: 14662.9326 - val_prd_loss_dig2phy_new: 21.2777\n",
      "Epoch 29/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 7672.6899 - prd_loss_dig2phy_new: 20.3268\n",
      "Epoch 29: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 42s 18ms/step - loss: 7666.1172 - prd_loss_dig2phy_new: 20.3364 - val_loss: 14670.9951 - val_prd_loss_dig2phy_new: 21.2695\n",
      "Epoch 30/30\n",
      "2307/2310 [============================>.] - ETA: 0s - loss: 7747.8594 - prd_loss_dig2phy_new: 20.2152\n",
      "Epoch 30: val_loss did not improve from 14600.75586\n",
      "2310/2310 [==============================] - 39s 17ms/step - loss: 7741.5415 - prd_loss_dig2phy_new: 20.2177 - val_loss: 14655.4053 - val_prd_loss_dig2phy_new: 21.2505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f17c0292af0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from qkeras import quantizers\n",
    "from qkeras import QConv1D, QDense, QActivation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qkeras import quantizers\n",
    "from qkeras import QConv1D, QDense, QActivation\n",
    "from qkeras.utils import load_qmodel\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the encoder with quantization\n",
    "input_ts = keras.layers.Input(shape=(64, 1), name=\"input_time_series\")  # 64, 1\n",
    "\n",
    "# First Conv1D layer with quantized activations\n",
    "x = QConv1D(8, 3, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same')(input_ts)  # 64, 16\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)  # Quantized activations to 16 bits\n",
    "# Second Conv1D layer with quantized activations\n",
    "x = QConv1D(8, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same')(x)  # 64, 16\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Third Conv1D layer with quantized activations\n",
    "x = QConv1D(4, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same', \n",
    "            strides=2)(x)  # 32, 8\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Fourth Conv1D layer with quantized activations\n",
    "x = QConv1D(4, 5, \n",
    "            kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "            bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1),\n",
    "            padding='same', \n",
    "            strides=2)(x)  # 16, 4\n",
    "x = QActivation(activation= quantizers.quantized_bits(28, 15, alpha=1))(x)\n",
    "# Flatten layer\n",
    "x = keras.layers.Flatten()(x)  # Flatten for Dense layer\n",
    "\n",
    "# Dense layer with quantized activations\n",
    "x = QDense(16, kernel_quantizer=quantizers.quantized_bits(12, 0, alpha=1), \n",
    "                 bias_quantizer=quantizers.quantized_bits(12, 0, alpha=1))(x)  # 16\n",
    "encoded = keras.layers.Activation(activation='linear')(x)\n",
    "\n",
    "# Define the model\n",
    "encoder = keras.models.Model(input_ts, encoded, name=\"encoder\")\n",
    "\n",
    "# Print the model summary\n",
    "encoder.summary()\n",
    "\n",
    "# Define the decoder\n",
    "encoded_input = keras.layers.Input(shape=(16,), name=\"encoded_input\") # 16\n",
    "x = keras.layers.Dense(16 * 4, activation='linear')(encoded_input) # 16 * 4\n",
    "x = keras.layers.Reshape((16, 4))(x) # Reshape back to (16, 4)\n",
    "x = keras.layers.Conv1DTranspose(8, 5, activation='linear', strides=2, padding='same')(x) # 16, 8\n",
    "x = keras.layers.Conv1DTranspose(16, 5, activation='linear', strides=2, padding='same')(x) # 32, 16\n",
    "x = keras.layers.Conv1DTranspose(8, 7, activation='linear', padding='same')(x) # 32, 16\n",
    "decoded = keras.layers.Conv1DTranspose(1, 3, activation='linear', padding='same')(x) # 64, 1\n",
    "\n",
    "decoder = keras.models.Model(encoded_input, decoded, name=\"decoder\")\n",
    "\n",
    "# Define the autoencoder\n",
    "autoencoder_input = keras.layers.Input(shape=(64, 1), name=\"autoencoder_input\")\n",
    "encoded_ts = encoder(autoencoder_input)\n",
    "decoded_ts = decoder(encoded_ts)\n",
    "\n",
    "autoencoder = keras.models.Model(autoencoder_input, decoded_ts, name=\"autoencoder\")\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.00001), loss=weighted_mse_loss, metrics=[prd_loss_dig2phy_new])\n",
    "weight_model = load_qmodel('quantised.h5', custom_objects={'prd_loss_dig2phy_new': prd_loss_dig2phy_new, 'weighted_mse_loss': weighted_mse_loss})\n",
    "# Summary of the autoencoder\n",
    "autoencoder.summary()\n",
    "autoencoder.set_weights(weight_model.get_weights())\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='inter1_quantised.h5',  # Path to save the model\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    save_best_only=True,       # Save only the best model\n",
    "    mode='min',                # Mode: minimize the monitored metric\n",
    "    verbose=1                  # Print a message when saving the model\n",
    ")\n",
    "#features_train = fuller_data[:, :, 0]\n",
    "# features_val = val_data[:, :, 0]\n",
    "\n",
    "new_train, new_val = train_test_split(fuller_data, test_size=0.2, random_state=69)\n",
    "features_val = new_val[:, :, 0]\n",
    "features_val = features_val[..., tf.newaxis]\n",
    "features_train = new_train[:, :, 0]\n",
    "features_train = features_train[..., tf.newaxis]\n",
    "pred = autoencoder.predict(features_val)\n",
    "print(prd_loss_dig2phy(features_val, pred).numpy())\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(features_train, new_train, epochs=30, batch_size=128, shuffle=True, callbacks=[checkpoint_callback], validation_data=(features_val, new_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2310/2310 [==============================] - 13s 6ms/step\n",
      "36.401436645508674\n",
      "2310/2310 [==============================] - 15s 6ms/step\n",
      "36.314028973267845\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import qkeras\n",
    "from qkeras.utils import load_qmodel\n",
    "from sklearn.model_selection import train_test_split    \n",
    "new_train, new_val = train_test_split(fuller_data, test_size=0.2, random_state=69)\n",
    "features_val = new_val[:, :, 0]\n",
    "features_val = features_val[..., tf.newaxis]\n",
    "features_train = new_train[:, :, 0]\n",
    "features_train = features_train[..., tf.newaxis]\n",
    "weight_model = load_qmodel('inter_quantised.h5', custom_objects={'prd_loss_dig2phy_new': prd_loss_dig2phy_new, 'weighted_mse_loss': weighted_mse_loss})\n",
    "lets = load_qmodel('real1_quantised.h5', custom_objects={'prd_loss_dig2phy_new': prd_loss_dig2phy_new, 'weighted_mse_loss': weighted_mse_loss})\n",
    "pred = lets.predict(features_val)\n",
    "print(prd_loss_dig2phy(features_val, pred).numpy())\n",
    "lets.set_weights(weight_model.get_weights())\n",
    "pred = lets.predict(features_val)\n",
    "print(prd_loss_dig2phy(features_val, pred).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qkeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
